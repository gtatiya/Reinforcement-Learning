Env: NovelGridworld-v0
Timesteps: 1500

model = DQN(MlpPolicy, env, verbose=1, tensorboard_log="./stable_baselines_DQN_tensorboard/", prioritized_replay=True)
model.learn(total_timesteps=1500)
===========================================

num_timesteps:  0
[[2.1185563 1.2817862 6.5447655]] - model q_values
[[2.1185563 1.2817862 6.5447655]] - step_model q_values
[[2.1185563 1.2817862 6.5447655]] - double_policy q_values
[[2.1185563 1.2817862 6.5447655]] - target_policy q_values

num_timesteps:  1
[[-0.44394433  0.9930157   3.1245413 ]] - model q_values
[[-0.44394433  0.9930157   3.1245413 ]] - step_model q_values
[[-0.44394433  0.9930157   3.1245413 ]] - double_policy q_values
[[-0.44394433  0.9930157   3.1245413 ]] - target_policy q_values

num_timesteps:  2
[[-0.30048442  0.8866829   5.005213  ]] - model q_values
[[-0.30048442  0.8866829   5.005213  ]] - step_model q_values
[[-0.30048442  0.8866829   5.005213  ]] - double_policy q_values
[[-0.30048442  0.8866829   5.005213  ]] - target_policy q_values

num_timesteps:  3
[[-0.44394433  0.9930157   3.1245413 ]] - model q_values
[[-0.44394433  0.9930157   3.1245413 ]] - step_model q_values
[[-0.44394433  0.9930157   3.1245413 ]] - double_policy q_values
[[-0.44394433  0.9930157   3.1245413 ]] - target_policy q_values

num_timesteps:  4
[[-0.3284558   0.96598923  3.6739244 ]] - model q_values
[[-0.3284558   0.96598923  3.6739244 ]] - step_model q_values
[[-0.3284558   0.96598923  3.6739244 ]] - double_policy q_values
[[-0.3284558   0.96598923  3.6739244 ]] - target_policy q_values

num_timesteps:  5
[[1.7030478 1.4251608 5.880868 ]] - model q_values
[[1.7030478 1.4251608 5.880868 ]] - step_model q_values
[[1.7030478 1.4251608 5.880868 ]] - double_policy q_values
[[1.7030478 1.4251608 5.880868 ]] - target_policy q_values

num_timesteps:  6
[[1.9354621 1.6924827 5.7600517]] - model q_values
[[1.9354621 1.6924827 5.7600517]] - step_model q_values
[[1.9354621 1.6924827 5.7600517]] - double_policy q_values
[[1.9354621 1.6924827 5.7600517]] - target_policy q_values

num_timesteps:  7
[[1.7030478 1.4251608 5.880868 ]] - model q_values
[[1.7030478 1.4251608 5.880868 ]] - step_model q_values
[[1.7030478 1.4251608 5.880868 ]] - double_policy q_values
[[1.7030478 1.4251608 5.880868 ]] - target_policy q_values

num_timesteps:  8
[[-0.3284558   0.96598923  3.6739244 ]] - model q_values
[[-0.3284558   0.96598923  3.6739244 ]] - step_model q_values
[[-0.3284558   0.96598923  3.6739244 ]] - double_policy q_values
[[-0.3284558   0.96598923  3.6739244 ]] - target_policy q_values

num_timesteps:  9
[[0.07800341 1.0722934  5.234832  ]] - model q_values
[[0.07800341 1.0722934  5.234832  ]] - step_model q_values
[[0.07800341 1.0722934  5.234832  ]] - double_policy q_values
[[0.07800341 1.0722934  5.234832  ]] - target_policy q_values

num_timesteps:  10
[[0.04922485 1.4179881  5.495359  ]] - model q_values
[[0.04922485 1.4179881  5.495359  ]] - step_model q_values
[[0.04922485 1.4179881  5.495359  ]] - double_policy q_values
[[0.04922485 1.4179881  5.495359  ]] - target_policy q_values

num_timesteps:  11
[[-0.87067854  0.8603629   3.084316  ]] - model q_values
[[-0.87067854  0.8603629   3.084316  ]] - step_model q_values
[[-0.87067854  0.8603629   3.084316  ]] - double_policy q_values
[[-0.87067854  0.8603629   3.084316  ]] - target_policy q_values

num_timesteps:  12
[[0.04922485 1.4179881  5.495359  ]] - model q_values
[[0.04922485 1.4179881  5.495359  ]] - step_model q_values
[[0.04922485 1.4179881  5.495359  ]] - double_policy q_values
[[0.04922485 1.4179881  5.495359  ]] - target_policy q_values

num_timesteps:  13
[[2.5757027 2.061234  6.0881104]] - model q_values
[[2.5757027 2.061234  6.0881104]] - step_model q_values
[[2.5757027 2.061234  6.0881104]] - double_policy q_values
[[2.5757027 2.061234  6.0881104]] - target_policy q_values

num_timesteps:  14
[[1.8759241 1.6536486 5.841408 ]] - model q_values
[[1.8759241 1.6536486 5.841408 ]] - step_model q_values
[[1.8759241 1.6536486 5.841408 ]] - double_policy q_values
[[1.8759241 1.6536486 5.841408 ]] - target_policy q_values

num_timesteps:  15
[[2.5757027 2.061234  6.0881104]] - model q_values
[[2.5757027 2.061234  6.0881104]] - step_model q_values
[[2.5757027 2.061234  6.0881104]] - double_policy q_values
[[2.5757027 2.061234  6.0881104]] - target_policy q_values

num_timesteps:  16
[[2.4065785 2.0385962 5.7433214]] - model q_values
[[2.4065785 2.0385962 5.7433214]] - step_model q_values
[[2.4065785 2.0385962 5.7433214]] - double_policy q_values
[[2.4065785 2.0385962 5.7433214]] - target_policy q_values

num_timesteps:  17
[[-0.3571186  1.316386   5.3206077]] - model q_values
[[-0.3571186  1.316386   5.3206077]] - step_model q_values
[[-0.3571186  1.316386   5.3206077]] - double_policy q_values
[[-0.3571186  1.316386   5.3206077]] - target_policy q_values

num_timesteps:  18
[[-0.3571186  1.316386   5.3206077]] - model q_values
[[-0.3571186  1.316386   5.3206077]] - step_model q_values
[[-0.3571186  1.316386   5.3206077]] - double_policy q_values
[[-0.3571186  1.316386   5.3206077]] - target_policy q_values

num_timesteps:  19
[[-0.8834817  0.9837525  2.6197124]] - model q_values
[[-0.8834817  0.9837525  2.6197124]] - step_model q_values
[[-0.8834817  0.9837525  2.6197124]] - double_policy q_values
[[-0.8834817  0.9837525  2.6197124]] - target_policy q_values

num_timesteps:  20
[[-0.3571186  1.316386   5.3206077]] - model q_values
[[-0.3571186  1.316386   5.3206077]] - step_model q_values
[[-0.3571186  1.316386   5.3206077]] - double_policy q_values
[[-0.3571186  1.316386   5.3206077]] - target_policy q_values

num_timesteps:  21
[[-0.3571186  1.316386   5.3206077]] - model q_values
[[-0.3571186  1.316386   5.3206077]] - step_model q_values
[[-0.3571186  1.316386   5.3206077]] - double_policy q_values
[[-0.3571186  1.316386   5.3206077]] - target_policy q_values

num_timesteps:  22
[[2.4065785 2.0385962 5.7433214]] - model q_values
[[2.4065785 2.0385962 5.7433214]] - step_model q_values
[[2.4065785 2.0385962 5.7433214]] - double_policy q_values
[[2.4065785 2.0385962 5.7433214]] - target_policy q_values

num_timesteps:  23
[[2.2878733 1.5030507 6.526133 ]] - model q_values
[[2.2878733 1.5030507 6.526133 ]] - step_model q_values
[[2.2878733 1.5030507 6.526133 ]] - double_policy q_values
[[2.2878733 1.5030507 6.526133 ]] - target_policy q_values

num_timesteps:  24
[[-0.8834817  0.9837525  2.6197124]] - model q_values
[[-0.8834817  0.9837525  2.6197124]] - step_model q_values
[[-0.8834817  0.9837525  2.6197124]] - double_policy q_values
[[-0.8834817  0.9837525  2.6197124]] - target_policy q_values

num_timesteps:  25
[[2.2878733 1.5030507 6.526133 ]] - model q_values
[[2.2878733 1.5030507 6.526133 ]] - step_model q_values
[[2.2878733 1.5030507 6.526133 ]] - double_policy q_values
[[2.2878733 1.5030507 6.526133 ]] - target_policy q_values

num_timesteps:  26
[[2.1185563 1.2817862 6.5447655]] - model q_values
[[2.1185563 1.2817862 6.5447655]] - step_model q_values
[[2.1185563 1.2817862 6.5447655]] - double_policy q_values
[[2.1185563 1.2817862 6.5447655]] - target_policy q_values

num_timesteps:  27
[[2.0590744 1.4259531 6.250065 ]] - model q_values
[[2.0590744 1.4259531 6.250065 ]] - step_model q_values
[[2.0590744 1.4259531 6.250065 ]] - double_policy q_values
[[2.0590744 1.4259531 6.250065 ]] - target_policy q_values

num_timesteps:  28
[[0.12614906 1.1788888  3.9400105 ]] - model q_values
[[0.12614906 1.1788888  3.9400105 ]] - step_model q_values
[[0.12614906 1.1788888  3.9400105 ]] - double_policy q_values
[[0.12614906 1.1788888  3.9400105 ]] - target_policy q_values

num_timesteps:  29
[[0.07083535 1.0443254  4.0590897 ]] - model q_values
[[0.07083535 1.0443254  4.0590897 ]] - step_model q_values
[[0.07083535 1.0443254  4.0590897 ]] - double_policy q_values
[[0.07083535 1.0443254  4.0590897 ]] - target_policy q_values

num_timesteps:  30
[[1.5225469 1.189048  5.9127026]] - model q_values
[[1.5225469 1.189048  5.9127026]] - step_model q_values
[[1.5225469 1.189048  5.9127026]] - double_policy q_values
[[1.5225469 1.189048  5.9127026]] - target_policy q_values

num_timesteps:  31
[[0.07083535 1.0443254  4.0590897 ]] - model q_values
[[0.07083535 1.0443254  4.0590897 ]] - step_model q_values
[[0.07083535 1.0443254  4.0590897 ]] - double_policy q_values
[[0.07083535 1.0443254  4.0590897 ]] - target_policy q_values

num_timesteps:  32
[[-0.37340713  1.215925    3.2566392 ]] - model q_values
[[-0.37340713  1.215925    3.2566392 ]] - step_model q_values
[[-0.37340713  1.215925    3.2566392 ]] - double_policy q_values
[[-0.37340713  1.215925    3.2566392 ]] - target_policy q_values

num_timesteps:  33
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  34
[[1.20008   1.909898  5.0986094]] - model q_values
[[1.20008   1.909898  5.0986094]] - step_model q_values
[[1.20008   1.909898  5.0986094]] - double_policy q_values
[[1.20008   1.909898  5.0986094]] - target_policy q_values

num_timesteps:  35
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  36
[[1.20008   1.909898  5.0986094]] - model q_values
[[1.20008   1.909898  5.0986094]] - step_model q_values
[[1.20008   1.909898  5.0986094]] - double_policy q_values
[[1.20008   1.909898  5.0986094]] - target_policy q_values

num_timesteps:  37
[[3.603202  3.3265038 3.5540457]] - model q_values
[[3.603202  3.3265038 3.5540457]] - step_model q_values
[[3.603202  3.3265038 3.5540457]] - double_policy q_values
[[3.603202  3.3265038 3.5540457]] - target_policy q_values

num_timesteps:  38
[[-0.37340713  1.215925    3.2566392 ]] - model q_values
[[-0.37340713  1.215925    3.2566392 ]] - step_model q_values
[[-0.37340713  1.215925    3.2566392 ]] - double_policy q_values
[[-0.37340713  1.215925    3.2566392 ]] - target_policy q_values

num_timesteps:  39
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  40
[[1.20008   1.909898  5.0986094]] - model q_values
[[1.20008   1.909898  5.0986094]] - step_model q_values
[[1.20008   1.909898  5.0986094]] - double_policy q_values
[[1.20008   1.909898  5.0986094]] - target_policy q_values

num_timesteps:  41
[[1.3102429 1.3939325 5.516928 ]] - model q_values
[[1.3102429 1.3939325 5.516928 ]] - step_model q_values
[[1.3102429 1.3939325 5.516928 ]] - double_policy q_values
[[1.3102429 1.3939325 5.516928 ]] - target_policy q_values

num_timesteps:  42
[[1.5225469 1.189048  5.9127026]] - model q_values
[[1.5225469 1.189048  5.9127026]] - step_model q_values
[[1.5225469 1.189048  5.9127026]] - double_policy q_values
[[1.5225469 1.189048  5.9127026]] - target_policy q_values

num_timesteps:  43
[[0.07083535 1.0443254  4.0590897 ]] - model q_values
[[0.07083535 1.0443254  4.0590897 ]] - step_model q_values
[[0.07083535 1.0443254  4.0590897 ]] - double_policy q_values
[[0.07083535 1.0443254  4.0590897 ]] - target_policy q_values

num_timesteps:  44
[[1.5225469 1.189048  5.9127026]] - model q_values
[[1.5225469 1.189048  5.9127026]] - step_model q_values
[[1.5225469 1.189048  5.9127026]] - double_policy q_values
[[1.5225469 1.189048  5.9127026]] - target_policy q_values

num_timesteps:  45
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  46
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  47
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  48
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  49
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  50
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  51
[[-0.29459023  0.9043307   4.7681975 ]] - model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - step_model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - double_policy q_values
[[-0.29459023  0.9043307   4.7681975 ]] - target_policy q_values

num_timesteps:  52
[[1.2995261 1.4719083 5.528407 ]] - model q_values
[[1.2995261 1.4719083 5.528407 ]] - step_model q_values
[[1.2995261 1.4719083 5.528407 ]] - double_policy q_values
[[1.2995261 1.4719083 5.528407 ]] - target_policy q_values

num_timesteps:  53
[[1.3765305 1.9663445 5.450673 ]] - model q_values
[[1.3765305 1.9663445 5.450673 ]] - step_model q_values
[[1.3765305 1.9663445 5.450673 ]] - double_policy q_values
[[1.3765305 1.9663445 5.450673 ]] - target_policy q_values

num_timesteps:  54
[[0.80183566 0.61660385 5.883283  ]] - model q_values
[[0.80183566 0.61660385 5.883283  ]] - step_model q_values
[[0.80183566 0.61660385 5.883283  ]] - double_policy q_values
[[0.80183566 0.61660385 5.883283  ]] - target_policy q_values

num_timesteps:  55
[[0.28280443 0.45451337 1.7257781 ]] - model q_values
[[0.28280443 0.45451337 1.7257781 ]] - step_model q_values
[[0.28280443 0.45451337 1.7257781 ]] - double_policy q_values
[[0.28280443 0.45451337 1.7257781 ]] - target_policy q_values

num_timesteps:  56
[[0.80183566 0.61660385 5.883283  ]] - model q_values
[[0.80183566 0.61660385 5.883283  ]] - step_model q_values
[[0.80183566 0.61660385 5.883283  ]] - double_policy q_values
[[0.80183566 0.61660385 5.883283  ]] - target_policy q_values

num_timesteps:  57
[[2.6527293 1.8062271 6.598828 ]] - model q_values
[[2.6527293 1.8062271 6.598828 ]] - step_model q_values
[[2.6527293 1.8062271 6.598828 ]] - double_policy q_values
[[2.6527293 1.8062271 6.598828 ]] - target_policy q_values

num_timesteps:  58
[[0.6112982 1.3859508 4.3115096]] - model q_values
[[0.6112982 1.3859508 4.3115096]] - step_model q_values
[[0.6112982 1.3859508 4.3115096]] - double_policy q_values
[[0.6112982 1.3859508 4.3115096]] - target_policy q_values

num_timesteps:  59
[[-0.7524674  0.9398519  3.932146 ]] - model q_values
[[-0.7524674  0.9398519  3.932146 ]] - step_model q_values
[[-0.7524674  0.9398519  3.932146 ]] - double_policy q_values
[[-0.7524674  0.9398519  3.932146 ]] - target_policy q_values

num_timesteps:  60
[[-0.74435604  0.9525748   4.170587  ]] - model q_values
[[-0.74435604  0.9525748   4.170587  ]] - step_model q_values
[[-0.74435604  0.9525748   4.170587  ]] - double_policy q_values
[[-0.74435604  0.9525748   4.170587  ]] - target_policy q_values

num_timesteps:  61
[[1.3765305 1.9663445 5.450673 ]] - model q_values
[[1.3765305 1.9663445 5.450673 ]] - step_model q_values
[[1.3765305 1.9663445 5.450673 ]] - double_policy q_values
[[1.3765305 1.9663445 5.450673 ]] - target_policy q_values

num_timesteps:  62
[[0.80183566 0.61660385 5.883283  ]] - model q_values
[[0.80183566 0.61660385 5.883283  ]] - step_model q_values
[[0.80183566 0.61660385 5.883283  ]] - double_policy q_values
[[0.80183566 0.61660385 5.883283  ]] - target_policy q_values

num_timesteps:  63
[[0.28280443 0.45451337 1.7257781 ]] - model q_values
[[0.28280443 0.45451337 1.7257781 ]] - step_model q_values
[[0.28280443 0.45451337 1.7257781 ]] - double_policy q_values
[[0.28280443 0.45451337 1.7257781 ]] - target_policy q_values

num_timesteps:  64
[[0.12614906 1.1788888  3.9400105 ]] - model q_values
[[0.12614906 1.1788888  3.9400105 ]] - step_model q_values
[[0.12614906 1.1788888  3.9400105 ]] - double_policy q_values
[[0.12614906 1.1788888  3.9400105 ]] - target_policy q_values

num_timesteps:  65
[[-0.29459023  0.9043307   4.7681975 ]] - model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - step_model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - double_policy q_values
[[-0.29459023  0.9043307   4.7681975 ]] - target_policy q_values

num_timesteps:  66
[[1.2995261 1.4719083 5.528407 ]] - model q_values
[[1.2995261 1.4719083 5.528407 ]] - step_model q_values
[[1.2995261 1.4719083 5.528407 ]] - double_policy q_values
[[1.2995261 1.4719083 5.528407 ]] - target_policy q_values

num_timesteps:  67
[[2.0590744 1.4259531 6.250065 ]] - model q_values
[[2.0590744 1.4259531 6.250065 ]] - step_model q_values
[[2.0590744 1.4259531 6.250065 ]] - double_policy q_values
[[2.0590744 1.4259531 6.250065 ]] - target_policy q_values

num_timesteps:  68
[[0.12614906 1.1788888  3.9400105 ]] - model q_values
[[0.12614906 1.1788888  3.9400105 ]] - step_model q_values
[[0.12614906 1.1788888  3.9400105 ]] - double_policy q_values
[[0.12614906 1.1788888  3.9400105 ]] - target_policy q_values

num_timesteps:  69
[[0.07083535 1.0443254  4.0590897 ]] - model q_values
[[0.07083535 1.0443254  4.0590897 ]] - step_model q_values
[[0.07083535 1.0443254  4.0590897 ]] - double_policy q_values
[[0.07083535 1.0443254  4.0590897 ]] - target_policy q_values

num_timesteps:  70
[[1.5225469 1.189048  5.9127026]] - model q_values
[[1.5225469 1.189048  5.9127026]] - step_model q_values
[[1.5225469 1.189048  5.9127026]] - double_policy q_values
[[1.5225469 1.189048  5.9127026]] - target_policy q_values

num_timesteps:  71
[[0.07083535 1.0443254  4.0590897 ]] - model q_values
[[0.07083535 1.0443254  4.0590897 ]] - step_model q_values
[[0.07083535 1.0443254  4.0590897 ]] - double_policy q_values
[[0.07083535 1.0443254  4.0590897 ]] - target_policy q_values

num_timesteps:  72
[[-0.37340713  1.215925    3.2566392 ]] - model q_values
[[-0.37340713  1.215925    3.2566392 ]] - step_model q_values
[[-0.37340713  1.215925    3.2566392 ]] - double_policy q_values
[[-0.37340713  1.215925    3.2566392 ]] - target_policy q_values

num_timesteps:  73
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  74
[[1.20008   1.909898  5.0986094]] - model q_values
[[1.20008   1.909898  5.0986094]] - step_model q_values
[[1.20008   1.909898  5.0986094]] - double_policy q_values
[[1.20008   1.909898  5.0986094]] - target_policy q_values

num_timesteps:  75
[[3.603202  3.3265038 3.5540457]] - model q_values
[[3.603202  3.3265038 3.5540457]] - step_model q_values
[[3.603202  3.3265038 3.5540457]] - double_policy q_values
[[3.603202  3.3265038 3.5540457]] - target_policy q_values

num_timesteps:  76
[[3.8402057 3.5223527 3.3584242]] - model q_values
[[3.8402057 3.5223527 3.3584242]] - step_model q_values
[[3.8402057 3.5223527 3.3584242]] - double_policy q_values
[[3.8402057 3.5223527 3.3584242]] - target_policy q_values

num_timesteps:  77
[[-0.03238261  1.5768147   3.568904  ]] - model q_values
[[-0.03238261  1.5768147   3.568904  ]] - step_model q_values
[[-0.03238261  1.5768147   3.568904  ]] - double_policy q_values
[[-0.03238261  1.5768147   3.568904  ]] - target_policy q_values

num_timesteps:  78
[[0.595953  1.0350266 5.2186756]] - model q_values
[[0.595953  1.0350266 5.2186756]] - step_model q_values
[[0.595953  1.0350266 5.2186756]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values

num_timesteps:  79
[[0.7339736 1.8273971 4.9202805]] - model q_values
[[0.7339736 1.8273971 4.9202805]] - step_model q_values
[[0.7339736 1.8273971 4.9202805]] - double_policy q_values
[[0.7339736 1.8273971 4.9202805]] - target_policy q_values

num_timesteps:  80
[[0.595953  1.0350266 5.2186756]] - model q_values
[[0.595953  1.0350266 5.2186756]] - step_model q_values
[[0.595953  1.0350266 5.2186756]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values

num_timesteps:  81
[[0.7339736 1.8273971 4.9202805]] - model q_values
[[0.7339736 1.8273971 4.9202805]] - step_model q_values
[[0.7339736 1.8273971 4.9202805]] - double_policy q_values
[[0.7339736 1.8273971 4.9202805]] - target_policy q_values

num_timesteps:  82
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  83
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  84
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  85
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  86
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  87
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  88
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  89
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  90
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  91
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  92
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  93
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  94
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  95
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  96
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  97
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  98
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  99
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  100
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  101
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  102
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  103
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  104
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  105
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  106
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  107
[[-0.29459023  0.9043307   4.7681975 ]] - model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - step_model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - double_policy q_values
[[-0.29459023  0.9043307   4.7681975 ]] - target_policy q_values

num_timesteps:  108
[[1.2995261 1.4719083 5.528407 ]] - model q_values
[[1.2995261 1.4719083 5.528407 ]] - step_model q_values
[[1.2995261 1.4719083 5.528407 ]] - double_policy q_values
[[1.2995261 1.4719083 5.528407 ]] - target_policy q_values

num_timesteps:  109
[[2.0590744 1.4259531 6.250065 ]] - model q_values
[[2.0590744 1.4259531 6.250065 ]] - step_model q_values
[[2.0590744 1.4259531 6.250065 ]] - double_policy q_values
[[2.0590744 1.4259531 6.250065 ]] - target_policy q_values

num_timesteps:  110
[[1.2995261 1.4719083 5.528407 ]] - model q_values
[[1.2995261 1.4719083 5.528407 ]] - step_model q_values
[[1.2995261 1.4719083 5.528407 ]] - double_policy q_values
[[1.2995261 1.4719083 5.528407 ]] - target_policy q_values

num_timesteps:  111
[[2.0590744 1.4259531 6.250065 ]] - model q_values
[[2.0590744 1.4259531 6.250065 ]] - step_model q_values
[[2.0590744 1.4259531 6.250065 ]] - double_policy q_values
[[2.0590744 1.4259531 6.250065 ]] - target_policy q_values

num_timesteps:  112
[[0.12614906 1.1788888  3.9400105 ]] - model q_values
[[0.12614906 1.1788888  3.9400105 ]] - step_model q_values
[[0.12614906 1.1788888  3.9400105 ]] - double_policy q_values
[[0.12614906 1.1788888  3.9400105 ]] - target_policy q_values

num_timesteps:  113
[[-0.29459023  0.9043307   4.7681975 ]] - model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - step_model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - double_policy q_values
[[-0.29459023  0.9043307   4.7681975 ]] - target_policy q_values

num_timesteps:  114
[[1.2995261 1.4719083 5.528407 ]] - model q_values
[[1.2995261 1.4719083 5.528407 ]] - step_model q_values
[[1.2995261 1.4719083 5.528407 ]] - double_policy q_values
[[1.2995261 1.4719083 5.528407 ]] - target_policy q_values

num_timesteps:  115
[[-0.29459023  0.9043307   4.7681975 ]] - model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - step_model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - double_policy q_values
[[-0.29459023  0.9043307   4.7681975 ]] - target_policy q_values

num_timesteps:  116
[[1.2995261 1.4719083 5.528407 ]] - model q_values
[[1.2995261 1.4719083 5.528407 ]] - step_model q_values
[[1.2995261 1.4719083 5.528407 ]] - double_policy q_values
[[1.2995261 1.4719083 5.528407 ]] - target_policy q_values

num_timesteps:  117
[[2.0590744 1.4259531 6.250065 ]] - model q_values
[[2.0590744 1.4259531 6.250065 ]] - step_model q_values
[[2.0590744 1.4259531 6.250065 ]] - double_policy q_values
[[2.0590744 1.4259531 6.250065 ]] - target_policy q_values

num_timesteps:  118
[[0.12614906 1.1788888  3.9400105 ]] - model q_values
[[0.12614906 1.1788888  3.9400105 ]] - step_model q_values
[[0.12614906 1.1788888  3.9400105 ]] - double_policy q_values
[[0.12614906 1.1788888  3.9400105 ]] - target_policy q_values

num_timesteps:  119
[[-0.29459023  0.9043307   4.7681975 ]] - model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - step_model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - double_policy q_values
[[-0.29459023  0.9043307   4.7681975 ]] - target_policy q_values

num_timesteps:  120
[[1.2995261 1.4719083 5.528407 ]] - model q_values
[[1.2995261 1.4719083 5.528407 ]] - step_model q_values
[[1.2995261 1.4719083 5.528407 ]] - double_policy q_values
[[1.2995261 1.4719083 5.528407 ]] - target_policy q_values

num_timesteps:  121
[[2.0590744 1.4259531 6.250065 ]] - model q_values
[[2.0590744 1.4259531 6.250065 ]] - step_model q_values
[[2.0590744 1.4259531 6.250065 ]] - double_policy q_values
[[2.0590744 1.4259531 6.250065 ]] - target_policy q_values

num_timesteps:  122
[[1.2995261 1.4719083 5.528407 ]] - model q_values
[[1.2995261 1.4719083 5.528407 ]] - step_model q_values
[[1.2995261 1.4719083 5.528407 ]] - double_policy q_values
[[1.2995261 1.4719083 5.528407 ]] - target_policy q_values

num_timesteps:  123
[[2.0590744 1.4259531 6.250065 ]] - model q_values
[[2.0590744 1.4259531 6.250065 ]] - step_model q_values
[[2.0590744 1.4259531 6.250065 ]] - double_policy q_values
[[2.0590744 1.4259531 6.250065 ]] - target_policy q_values

num_timesteps:  124
[[0.12614906 1.1788888  3.9400105 ]] - model q_values
[[0.12614906 1.1788888  3.9400105 ]] - step_model q_values
[[0.12614906 1.1788888  3.9400105 ]] - double_policy q_values
[[0.12614906 1.1788888  3.9400105 ]] - target_policy q_values

num_timesteps:  125
[[-0.29459023  0.9043307   4.7681975 ]] - model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - step_model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - double_policy q_values
[[-0.29459023  0.9043307   4.7681975 ]] - target_policy q_values

num_timesteps:  126
[[1.2995261 1.4719083 5.528407 ]] - model q_values
[[1.2995261 1.4719083 5.528407 ]] - step_model q_values
[[1.2995261 1.4719083 5.528407 ]] - double_policy q_values
[[1.2995261 1.4719083 5.528407 ]] - target_policy q_values

num_timesteps:  127
[[2.0590744 1.4259531 6.250065 ]] - model q_values
[[2.0590744 1.4259531 6.250065 ]] - step_model q_values
[[2.0590744 1.4259531 6.250065 ]] - double_policy q_values
[[2.0590744 1.4259531 6.250065 ]] - target_policy q_values

num_timesteps:  128
[[0.12614906 1.1788888  3.9400105 ]] - model q_values
[[0.12614906 1.1788888  3.9400105 ]] - step_model q_values
[[0.12614906 1.1788888  3.9400105 ]] - double_policy q_values
[[0.12614906 1.1788888  3.9400105 ]] - target_policy q_values

num_timesteps:  129
[[-0.29459023  0.9043307   4.7681975 ]] - model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - step_model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - double_policy q_values
[[-0.29459023  0.9043307   4.7681975 ]] - target_policy q_values

num_timesteps:  130
[[0.12614906 1.1788888  3.9400105 ]] - model q_values
[[0.12614906 1.1788888  3.9400105 ]] - step_model q_values
[[0.12614906 1.1788888  3.9400105 ]] - double_policy q_values
[[0.12614906 1.1788888  3.9400105 ]] - target_policy q_values

num_timesteps:  131
[[-0.29459023  0.9043307   4.7681975 ]] - model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - step_model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - double_policy q_values
[[-0.29459023  0.9043307   4.7681975 ]] - target_policy q_values

num_timesteps:  132
[[1.2995261 1.4719083 5.528407 ]] - model q_values
[[1.2995261 1.4719083 5.528407 ]] - step_model q_values
[[1.2995261 1.4719083 5.528407 ]] - double_policy q_values
[[1.2995261 1.4719083 5.528407 ]] - target_policy q_values

num_timesteps:  133
[[2.0590744 1.4259531 6.250065 ]] - model q_values
[[2.0590744 1.4259531 6.250065 ]] - step_model q_values
[[2.0590744 1.4259531 6.250065 ]] - double_policy q_values
[[2.0590744 1.4259531 6.250065 ]] - target_policy q_values

num_timesteps:  134
[[0.12614906 1.1788888  3.9400105 ]] - model q_values
[[0.12614906 1.1788888  3.9400105 ]] - step_model q_values
[[0.12614906 1.1788888  3.9400105 ]] - double_policy q_values
[[0.12614906 1.1788888  3.9400105 ]] - target_policy q_values

num_timesteps:  135
[[-0.29459023  0.9043307   4.7681975 ]] - model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - step_model q_values
[[-0.29459023  0.9043307   4.7681975 ]] - double_policy q_values
[[-0.29459023  0.9043307   4.7681975 ]] - target_policy q_values

num_timesteps:  136
[[1.2995261 1.4719083 5.528407 ]] - model q_values
[[1.2995261 1.4719083 5.528407 ]] - step_model q_values
[[1.2995261 1.4719083 5.528407 ]] - double_policy q_values
[[1.2995261 1.4719083 5.528407 ]] - target_policy q_values

num_timesteps:  137
[[2.0590744 1.4259531 6.250065 ]] - model q_values
[[2.0590744 1.4259531 6.250065 ]] - step_model q_values
[[2.0590744 1.4259531 6.250065 ]] - double_policy q_values
[[2.0590744 1.4259531 6.250065 ]] - target_policy q_values

num_timesteps:  138
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  139
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  140
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  141
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  142
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  143
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  144
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  145
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  146
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  147
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  148
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  149
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  150
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  151
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  152
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  153
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  154
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  155
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  156
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  157
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  158
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  159
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  160
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  161
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  162
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  163
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  164
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  165
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  166
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  167
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  168
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  169
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  170
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  171
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  172
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  173
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  174
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  175
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  176
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  177
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  178
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  179
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  180
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  181
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  182
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  183
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  184
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  185
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  186
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  187
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  188
[[-0.24679005  0.95634454  4.49942   ]] - model q_values
[[-0.24679005  0.95634454  4.49942   ]] - step_model q_values
[[-0.24679005  0.95634454  4.49942   ]] - double_policy q_values
[[-0.24679005  0.95634454  4.49942   ]] - target_policy q_values

num_timesteps:  189
[[0.8951709 1.3528866 5.4105983]] - model q_values
[[0.8951709 1.3528866 5.4105983]] - step_model q_values
[[0.8951709 1.3528866 5.4105983]] - double_policy q_values
[[0.8951709 1.3528866 5.4105983]] - target_policy q_values

num_timesteps:  190
[[0.17728448 0.21801615 5.510341  ]] - model q_values
[[0.17728448 0.21801615 5.510341  ]] - step_model q_values
[[0.17728448 0.21801615 5.510341  ]] - double_policy q_values
[[0.17728448 0.21801615 5.510341  ]] - target_policy q_values

num_timesteps:  191
[[0.47334498 0.0957424  1.885564  ]] - model q_values
[[0.47334498 0.0957424  1.885564  ]] - step_model q_values
[[0.47334498 0.0957424  1.885564  ]] - double_policy q_values
[[0.47334498 0.0957424  1.885564  ]] - target_policy q_values

num_timesteps:  192
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  193
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  194
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  195
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  196
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  197
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  198
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  199
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  200
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  201
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  202
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  203
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  204
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  205
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  206
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  207
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  208
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  209
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  210
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  211
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  212
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  213
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  214
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  215
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  216
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  217
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  218
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  219
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  220
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  221
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  222
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  223
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  224
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  225
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  226
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  227
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  228
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  229
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  230
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  231
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  232
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  233
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  234
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  235
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  236
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  237
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  238
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  239
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  240
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  241
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  242
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  243
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  244
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  245
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  246
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  247
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  248
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  249
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  250
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  251
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  252
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  253
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  254
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  255
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  256
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  257
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  258
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  259
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  260
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  261
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  262
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  263
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  264
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  265
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  266
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  267
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  268
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  269
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  270
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  271
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  272
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  273
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  274
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  275
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  276
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  277
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  278
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  279
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  280
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  281
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  282
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  283
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  284
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  285
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  286
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  287
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  288
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  289
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  290
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  291
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  292
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  293
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  294
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  295
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  296
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  297
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  298
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  299
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  300
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  301
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  302
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  303
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  304
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  305
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  306
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  307
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  308
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  309
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  310
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  311
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  312
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  313
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  314
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  315
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  316
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  317
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  318
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  319
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  320
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  321
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  322
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  323
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  324
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  325
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  326
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  327
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  328
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  329
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  330
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  331
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  332
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  333
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  334
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  335
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  336
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  337
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  338
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  339
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  340
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  341
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  342
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  343
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  344
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  345
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  346
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  347
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  348
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  349
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  350
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  351
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  352
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  353
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  354
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  355
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  356
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  357
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  358
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  359
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  360
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  361
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  362
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  363
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  364
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  365
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  366
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  367
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  368
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  369
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  370
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  371
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  372
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  373
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  374
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  375
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  376
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  377
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  378
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  379
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  380
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  381
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  382
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  383
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  384
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  385
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  386
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  387
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  388
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  389
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  390
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  391
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  392
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  393
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  394
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  395
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  396
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  397
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  398
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  399
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  400
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  401
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  402
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  403
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  404
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  405
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  406
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  407
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  408
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  409
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  410
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  411
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  412
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  413
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  414
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  415
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  416
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  417
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  418
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  419
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  420
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  421
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  422
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  423
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  424
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  425
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  426
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  427
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  428
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  429
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  430
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  431
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  432
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  433
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  434
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  435
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  436
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  437
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  438
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  439
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  440
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  441
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  442
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  443
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  444
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  445
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  446
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  447
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  448
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  449
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  450
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  451
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  452
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  453
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  454
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  455
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  456
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  457
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  458
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  459
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  460
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  461
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  462
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  463
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  464
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  465
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  466
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  467
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  468
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  469
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  470
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  471
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  472
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  473
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  474
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  475
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  476
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  477
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  478
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  479
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  480
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  481
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  482
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  483
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  484
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  485
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  486
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  487
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  488
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  489
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  490
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  491
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  492
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  493
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  494
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  495
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  496
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  497
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  498
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  499
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  500
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  501
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  502
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  503
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  504
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  505
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  506
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  507
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  508
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  509
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  510
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  511
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  512
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  513
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  514
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  515
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  516
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  517
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  518
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  519
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  520
[[0.53559434 1.177874   4.6113625 ]] - model q_values
[[0.53559434 1.177874   4.6113625 ]] - step_model q_values
[[0.53559434 1.177874   4.6113625 ]] - double_policy q_values
[[0.53559434 1.177874   4.6113625 ]] - target_policy q_values

num_timesteps:  521
[[0.21122122 1.0251747  4.8782263 ]] - model q_values
[[0.21122122 1.0251747  4.8782263 ]] - step_model q_values
[[0.21122122 1.0251747  4.8782263 ]] - double_policy q_values
[[0.21122122 1.0251747  4.8782263 ]] - target_policy q_values

num_timesteps:  522
[[0.9409028 1.25072   5.4148045]] - model q_values
[[0.9409028 1.25072   5.4148045]] - step_model q_values
[[0.9409028 1.25072   5.4148045]] - double_policy q_values
[[0.9409028 1.25072   5.4148045]] - target_policy q_values

num_timesteps:  523
[[1.4322425 1.2111766 5.8347464]] - model q_values
[[1.4322425 1.2111766 5.8347464]] - step_model q_values
[[1.4322425 1.2111766 5.8347464]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values

num_timesteps:  524
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  525
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  526
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  527
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  528
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  529
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  530
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  531
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  532
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  533
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  534
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  535
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  536
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  537
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  538
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  539
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  540
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  541
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  542
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  543
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  544
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  545
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  546
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  547
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  548
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  549
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  550
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  551
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  552
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  553
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  554
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  555
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  556
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  557
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  558
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  559
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  560
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  561
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  562
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  563
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  564
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  565
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  566
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  567
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  568
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  569
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  570
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  571
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  572
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  573
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  574
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  575
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  576
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  577
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  578
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  579
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  580
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  581
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  582
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  583
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  584
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  585
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  586
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  587
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  588
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  589
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  590
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  591
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  592
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  593
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  594
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  595
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  596
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  597
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  598
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  599
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  600
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  601
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  602
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  603
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  604
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  605
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  606
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  607
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  608
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  609
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  610
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  611
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  612
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  613
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  614
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  615
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  616
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  617
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  618
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  619
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  620
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  621
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  622
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  623
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  624
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  625
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  626
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  627
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  628
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  629
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  630
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  631
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  632
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  633
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  634
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  635
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  636
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  637
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  638
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  639
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  640
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  641
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  642
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  643
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  644
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  645
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  646
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  647
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  648
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  649
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  650
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  651
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  652
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  653
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  654
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  655
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  656
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  657
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  658
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  659
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  660
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  661
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  662
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  663
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  664
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  665
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  666
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  667
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  668
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  669
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  670
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  671
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  672
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  673
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  674
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  675
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  676
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  677
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  678
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  679
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  680
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  681
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  682
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  683
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  684
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  685
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  686
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  687
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  688
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  689
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  690
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  691
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  692
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  693
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  694
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  695
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  696
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  697
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  698
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  699
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  700
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  701
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  702
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  703
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  704
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  705
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  706
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  707
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  708
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  709
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  710
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  711
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  712
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  713
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  714
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  715
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  716
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  717
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  718
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  719
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  720
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  721
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  722
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  723
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  724
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  725
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  726
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  727
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  728
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  729
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  730
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  731
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  732
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  733
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  734
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  735
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  736
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  737
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  738
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  739
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  740
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  741
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  742
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  743
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  744
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  745
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  746
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  747
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  748
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  749
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  750
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  751
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  752
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  753
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  754
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  755
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  756
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  757
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  758
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  759
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  760
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  761
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  762
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  763
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  764
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  765
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  766
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  767
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  768
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  769
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  770
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  771
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  772
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  773
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  774
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  775
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  776
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  777
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  778
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  779
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  780
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  781
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  782
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  783
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  784
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  785
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  786
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  787
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  788
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  789
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  790
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  791
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  792
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  793
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  794
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  795
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  796
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  797
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  798
[[-0.42676353 -0.1566217   5.226044  ]] - model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - step_model q_values
[[-0.42676353 -0.1566217   5.226044  ]] - double_policy q_values
[[-0.42676353 -0.1566217   5.226044  ]] - target_policy q_values

num_timesteps:  799
[[ 0.59983414 -0.6740106   1.9332051 ]] - model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - step_model q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - double_policy q_values
[[ 0.59983414 -0.6740106   1.9332051 ]] - target_policy q_values

num_timesteps:  800
[[0.08995771 0.96927834 4.3532004 ]] - model q_values
[[0.08995771 0.96927834 4.3532004 ]] - step_model q_values
[[0.08995771 0.96927834 4.3532004 ]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values

num_timesteps:  801
[[0.5774921 1.1709594 5.316329 ]] - model q_values
[[0.5774921 1.1709594 5.316329 ]] - step_model q_values
[[0.5774921 1.1709594 5.316329 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values

num_timesteps:  802
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  803
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  804
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  805
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  806
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  807
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  808
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  809
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  810
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  811
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  812
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  813
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  814
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  815
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  816
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  817
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  818
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  819
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  820
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  821
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  822
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  823
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  824
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  825
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  826
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  827
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  828
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  829
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  830
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  831
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  832
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  833
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  834
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  835
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  836
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  837
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  838
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  839
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  840
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  841
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  842
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  843
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  844
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  845
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  846
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  847
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  848
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  849
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  850
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  851
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  852
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  853
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  854
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  855
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  856
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  857
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  858
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  859
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  860
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  861
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  862
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  863
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  864
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  865
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  866
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  867
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  868
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  869
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  870
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  871
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  872
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  873
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  874
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  875
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  876
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  877
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  878
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  879
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  880
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  881
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  882
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  883
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  884
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  885
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  886
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  887
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  888
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  889
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  890
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  891
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  892
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  893
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  894
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  895
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  896
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  897
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  898
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  899
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  900
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  901
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  902
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  903
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  904
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  905
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  906
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  907
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  908
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  909
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  910
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  911
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  912
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  913
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  914
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  915
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  916
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  917
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  918
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  919
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  920
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  921
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  922
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  923
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  924
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  925
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  926
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  927
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  928
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  929
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  930
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  931
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  932
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  933
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  934
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  935
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  936
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  937
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  938
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  939
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  940
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  941
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  942
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  943
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  944
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  945
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  946
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  947
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  948
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  949
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  950
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  951
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  952
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  953
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  954
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  955
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  956
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  957
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  958
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  959
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  960
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  961
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  962
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  963
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  964
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  965
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  966
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  967
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  968
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  969
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  970
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  971
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  972
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  973
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  974
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  975
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  976
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  977
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  978
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  979
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  980
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  981
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  982
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  983
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  984
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  985
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  986
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  987
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  988
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  989
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  990
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  991
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  992
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  993
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  994
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  995
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  996
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values

num_timesteps:  997
[[-0.29712677  0.8986474   3.997241  ]] - model q_values
[[-0.29712677  0.8986474   3.997241  ]] - step_model q_values
[[-0.29712677  0.8986474   3.997241  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values

num_timesteps:  998
[[0.48293817 1.2397107  5.3261085 ]] - model q_values
[[0.48293817 1.2397107  5.3261085 ]] - step_model q_values
[[0.48293817 1.2397107  5.3261085 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values

num_timesteps:  999
[[2.012568  1.6576153 5.900246 ]] - model q_values
[[2.012568  1.6576153 5.900246 ]] - step_model q_values
[[2.012568  1.6576153 5.900246 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values

num_timesteps:  1000
[[1.2305678 1.3680463 5.2540035]] - model q_values
[[1.2305678 1.3680463 5.2540035]] - step_model q_values
[[1.2305678 1.3680463 5.2540035]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1001
[[-0.4902954  0.8514213  3.039599 ]] - model q_values
[[-0.4902954  0.8514213  3.039599 ]] - step_model q_values
[[-0.4902954  0.8514213  3.039599 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1002
[[0.21028817 1.2135544  3.9252462 ]] - model q_values
[[0.21028817 1.2135544  3.9252462 ]] - step_model q_values
[[0.21028817 1.2135544  3.9252462 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1003
[[1.5809056 1.5520109 3.9217625]] - model q_values
[[1.5809056 1.5520109 3.9217625]] - step_model q_values
[[1.5809056 1.5520109 3.9217625]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1004
[[0.7481699 1.2087328 3.1107492]] - model q_values
[[0.7481699 1.2087328 3.1107492]] - step_model q_values
[[0.7481699 1.2087328 3.1107492]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1005
[[-0.68281454  0.8254024   2.2939997 ]] - model q_values
[[-0.68281454  0.8254024   2.2939997 ]] - step_model q_values
[[-0.68281454  0.8254024   2.2939997 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1006
[[0.08457565 1.1392493  3.6524324 ]] - model q_values
[[0.08457565 1.1392493  3.6524324 ]] - step_model q_values
[[0.08457565 1.1392493  3.6524324 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1007
[[1.5622728 1.4879627 3.7174354]] - model q_values
[[1.5622728 1.4879627 3.7174354]] - step_model q_values
[[1.5622728 1.4879627 3.7174354]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1008
[[0.7807594 1.1694871 3.3476858]] - model q_values
[[0.7807594 1.1694871 3.3476858]] - step_model q_values
[[0.7807594 1.1694871 3.3476858]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1009
[[-0.53499913  0.85604084  3.0629737 ]] - model q_values
[[-0.53499913  0.85604084  3.0629737 ]] - step_model q_values
[[-0.53499913  0.85604084  3.0629737 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1010
[[0.14637065 1.0974227  4.3269854 ]] - model q_values
[[0.14637065 1.0974227  4.3269854 ]] - step_model q_values
[[0.14637065 1.0974227  4.3269854 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1011
[[1.6737113 1.4517109 4.2798357]] - model q_values
[[1.6737113 1.4517109 4.2798357]] - step_model q_values
[[1.6737113 1.4517109 4.2798357]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1012
[[0.9161062 1.2179103 4.0289083]] - model q_values
[[0.9161062 1.2179103 4.0289083]] - step_model q_values
[[0.9161062 1.2179103 4.0289083]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1013
[[-0.32686698  0.9585414   3.9684005 ]] - model q_values
[[-0.32686698  0.9585414   3.9684005 ]] - step_model q_values
[[-0.32686698  0.9585414   3.9684005 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1014
[[0.21330273 1.1185514  4.905025  ]] - model q_values
[[0.21330273 1.1185514  4.905025  ]] - step_model q_values
[[0.21330273 1.1185514  4.905025  ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1015
[[1.7728183 1.4871978 4.565786 ]] - model q_values
[[1.7728183 1.4871978 4.565786 ]] - step_model q_values
[[1.7728183 1.4871978 4.565786 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1016
[[1.0092653 1.2941347 4.1798654]] - model q_values
[[1.0092653 1.2941347 4.1798654]] - step_model q_values
[[1.0092653 1.2941347 4.1798654]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1017
[[-0.21741521  1.0734143   4.2616777 ]] - model q_values
[[-0.21741521  1.0734143   4.2616777 ]] - step_model q_values
[[-0.21741521  1.0734143   4.2616777 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1018
[[0.2606995 1.1817238 4.8735046]] - model q_values
[[0.2606995 1.1817238 4.8735046]] - step_model q_values
[[0.2606995 1.1817238 4.8735046]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1019
[[1.8005626 1.5676854 4.2035756]] - model q_values
[[1.8005626 1.5676854 4.2035756]] - step_model q_values
[[1.8005626 1.5676854 4.2035756]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1020
[[1.0353438 1.370646  3.7157562]] - model q_values
[[1.0353438 1.370646  3.7157562]] - step_model q_values
[[1.0353438 1.370646  3.7157562]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1021
[[-0.18909323  1.1640416   4.0985107 ]] - model q_values
[[-0.18909323  1.1640416   4.0985107 ]] - step_model q_values
[[-0.18909323  1.1640416   4.0985107 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1022
[[0.30089235 1.2509724  4.5928445 ]] - model q_values
[[0.30089235 1.2509724  4.5928445 ]] - step_model q_values
[[0.30089235 1.2509724  4.5928445 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1023
[[1.8030866 1.6361613 3.7703676]] - model q_values
[[1.8030866 1.6361613 3.7703676]] - step_model q_values
[[1.8030866 1.6361613 3.7703676]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1024
[[1.049164  1.4347357 3.284891 ]] - model q_values
[[1.049164  1.4347357 3.284891 ]] - step_model q_values
[[1.049164  1.4347357 3.284891 ]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1025
[[-0.18087828  1.2283928   3.949639  ]] - model q_values
[[-0.18087828  1.2283928   3.949639  ]] - step_model q_values
[[-0.18087828  1.2283928   3.949639  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1026
[[0.33543706 1.3103325  4.4173517 ]] - model q_values
[[0.33543706 1.3103325  4.4173517 ]] - step_model q_values
[[0.33543706 1.3103325  4.4173517 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1027
[[1.8199    1.698024  3.5395107]] - model q_values
[[1.8199    1.698024  3.5395107]] - step_model q_values
[[1.8199    1.698024  3.5395107]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1028
[[1.0785316 1.4984138 3.1008067]] - model q_values
[[1.0785316 1.4984138 3.1008067]] - step_model q_values
[[1.0785316 1.4984138 3.1008067]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1029
[[-0.13353884  1.2944661   3.9616323 ]] - model q_values
[[-0.13353884  1.2944661   3.9616323 ]] - step_model q_values
[[-0.13353884  1.2944661   3.9616323 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1030
[[0.36801076 1.3621266  4.433685  ]] - model q_values
[[0.36801076 1.3621266  4.433685  ]] - step_model q_values
[[0.36801076 1.3621266  4.433685  ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1031
[[1.8506837 1.7567275 3.5465624]] - model q_values
[[1.8506837 1.7567275 3.5465624]] - step_model q_values
[[1.8506837 1.7567275 3.5465624]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1032
[[1.1175855 1.562803  3.152628 ]] - model q_values
[[1.1175855 1.562803  3.152628 ]] - step_model q_values
[[1.1175855 1.562803  3.152628 ]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1033
[[-0.05251229  1.3820765   4.139448  ]] - model q_values
[[-0.05251229  1.3820765   4.139448  ]] - step_model q_values
[[-0.05251229  1.3820765   4.139448  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1034
[[0.4102664 1.4162166 4.5770216]] - model q_values
[[0.4102664 1.4162166 4.5770216]] - step_model q_values
[[0.4102664 1.4162166 4.5770216]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1035
[[1.8994826 1.8223393 3.688075 ]] - model q_values
[[1.8994826 1.8223393 3.688075 ]] - step_model q_values
[[1.8994826 1.8223393 3.688075 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1036
[[1.198568  1.665192  3.3572073]] - model q_values
[[1.198568  1.665192  3.3572073]] - step_model q_values
[[1.198568  1.665192  3.3572073]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1037
[[0.07238066 1.4972823  4.3902717 ]] - model q_values
[[0.07238066 1.4972823  4.3902717 ]] - step_model q_values
[[0.07238066 1.4972823  4.3902717 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1038
[[0.49511492 1.5050486  4.795044  ]] - model q_values
[[0.49511492 1.5050486  4.795044  ]] - step_model q_values
[[0.49511492 1.5050486  4.795044  ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1039
[[1.960057  1.8943366 3.8523216]] - model q_values
[[1.960057  1.8943366 3.8523216]] - step_model q_values
[[1.960057  1.8943366 3.8523216]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1040
[[1.3052318 1.7805923 3.5497065]] - model q_values
[[1.3052318 1.7805923 3.5497065]] - step_model q_values
[[1.3052318 1.7805923 3.5497065]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1041
[[0.1835208 1.5967252 4.5707135]] - model q_values
[[0.1835208 1.5967252 4.5707135]] - step_model q_values
[[0.1835208 1.5967252 4.5707135]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1042
[[0.56731176 1.5780656  4.926059  ]] - model q_values
[[0.56731176 1.5780656  4.926059  ]] - step_model q_values
[[0.56731176 1.5780656  4.926059  ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1043
[[2.0328069 1.9745946 3.9464746]] - model q_values
[[2.0328069 1.9745946 3.9464746]] - step_model q_values
[[2.0328069 1.9745946 3.9464746]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1044
[[1.3703799 1.8545103 3.6125605]] - model q_values
[[1.3703799 1.8545103 3.6125605]] - step_model q_values
[[1.3703799 1.8545103 3.6125605]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1045
[[0.24320924 1.6598035  4.6291056 ]] - model q_values
[[0.24320924 1.6598035  4.6291056 ]] - step_model q_values
[[0.24320924 1.6598035  4.6291056 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1046
[[0.60822153 1.6270306  4.9516916 ]] - model q_values
[[0.60822153 1.6270306  4.9516916 ]] - step_model q_values
[[0.60822153 1.6270306  4.9516916 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1047
[[2.0718226 2.0249333 3.93752  ]] - model q_values
[[2.0718226 2.0249333 3.93752  ]] - step_model q_values
[[2.0718226 2.0249333 3.93752  ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  4.932618

num_timesteps:  1048
[[1.4048212 1.8994663 3.5698514]] - model q_values
[[1.4048212 1.8994663 3.5698514]] - step_model q_values
[[1.4048212 1.8994663 3.5698514]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1049
[[0.27113616 1.7002155  4.6001363 ]] - model q_values
[[0.27113616 1.7002155  4.6001363 ]] - step_model q_values
[[0.27113616 1.7002155  4.6001363 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1050
[[0.631307  1.6628551 4.900077 ]] - model q_values
[[0.631307  1.6628551 4.900077 ]] - step_model q_values
[[0.631307  1.6628551 4.900077 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1051
[[2.0936775 2.0644665 3.8577569]] - model q_values
[[2.0936775 2.0644665 3.8577569]] - step_model q_values
[[2.0936775 2.0644665 3.8577569]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1052
[[1.426063  1.9351078 3.4630327]] - model q_values
[[1.426063  1.9351078 3.4630327]] - step_model q_values
[[1.426063  1.9351078 3.4630327]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1053
[[0.28416753 1.7360344  4.523118  ]] - model q_values
[[0.28416753 1.7360344  4.523118  ]] - step_model q_values
[[0.28416753 1.7360344  4.523118  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1054
[[0.64743996 1.7001185  4.8123236 ]] - model q_values
[[0.64743996 1.7001185  4.8123236 ]] - step_model q_values
[[0.64743996 1.7001185  4.8123236 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1055
[[2.1061735 2.1027102 3.7478878]] - model q_values
[[2.1061735 2.1027102 3.7478878]] - step_model q_values
[[2.1061735 2.1027102 3.7478878]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1056
[[1.4349198 1.9649321 3.3297477]] - model q_values
[[1.4349198 1.9649321 3.3297477]] - step_model q_values
[[1.4349198 1.9649321 3.3297477]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1057
[[0.28690004 1.764735   4.4295874 ]] - model q_values
[[0.28690004 1.764735   4.4295874 ]] - step_model q_values
[[0.28690004 1.764735   4.4295874 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1058
[[0.66159976 1.7333808  4.7264338 ]] - model q_values
[[0.66159976 1.7333808  4.7264338 ]] - step_model q_values
[[0.66159976 1.7333808  4.7264338 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1059
[[2.1274176 2.1463673 3.6637363]] - model q_values
[[2.1274176 2.1463673 3.6637363]] - step_model q_values
[[2.1274176 2.1463673 3.6637363]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1060
[[1.4691868 2.0151224 3.2536812]] - model q_values
[[1.4691868 2.0151224 3.2536812]] - step_model q_values
[[1.4691868 2.0151224 3.2536812]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1061
[[0.3264953 1.8214438 4.3975043]] - model q_values
[[0.3264953 1.8214438 4.3975043]] - step_model q_values
[[0.3264953 1.8214438 4.3975043]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1062
[[0.7131007 1.7959869 4.7142735]] - model q_values
[[0.7131007 1.7959869 4.7142735]] - step_model q_values
[[0.7131007 1.7959869 4.7142735]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1063
[[2.198437  2.2272556 3.6796842]] - model q_values
[[2.198437  2.2272556 3.6796842]] - step_model q_values
[[2.198437  2.2272556 3.6796842]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1064
[[1.5417498 2.0963035 3.2698758]] - model q_values
[[1.5417498 2.0963035 3.2698758]] - step_model q_values
[[1.5417498 2.0963035 3.2698758]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1065
[[0.3914348 1.8938177 4.427584 ]] - model q_values
[[0.3914348 1.8938177 4.427584 ]] - step_model q_values
[[0.3914348 1.8938177 4.427584 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1066
[[0.7740803 1.8637648 4.7543755]] - model q_values
[[0.7740803 1.8637648 4.7543755]] - step_model q_values
[[0.7740803 1.8637648 4.7543755]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1067
[[2.2766125 2.3186235 3.751639 ]] - model q_values
[[2.2766125 2.3186235 3.751639 ]] - step_model q_values
[[2.2766125 2.3186235 3.751639 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1068
[[1.6175885 2.184965  3.3426504]] - model q_values
[[1.6175885 2.184965  3.3426504]] - step_model q_values
[[1.6175885 2.184965  3.3426504]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1069
[[0.4639356 1.9704502 4.4932036]] - model q_values
[[0.4639356 1.9704502 4.4932036]] - step_model q_values
[[0.4639356 1.9704502 4.4932036]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1070
[[0.84194374 1.9376779  4.828488  ]] - model q_values
[[0.84194374 1.9376779  4.828488  ]] - step_model q_values
[[0.84194374 1.9376779  4.828488  ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1071
[[2.3665318 2.415782  3.8567743]] - model q_values
[[2.3665318 2.415782  3.8567743]] - step_model q_values
[[2.3665318 2.415782  3.8567743]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1072
[[1.700782  2.2746015 3.4288075]] - model q_values
[[1.700782  2.2746015 3.4288075]] - step_model q_values
[[1.700782  2.2746015 3.4288075]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1073
[[0.5384549 2.0447583 4.552587 ]] - model q_values
[[0.5384549 2.0447583 4.552587 ]] - step_model q_values
[[0.5384549 2.0447583 4.552587 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1074
[[0.9091513 2.00775   4.8755627]] - model q_values
[[0.9091513 2.00775   4.8755627]] - step_model q_values
[[0.9091513 2.00775   4.8755627]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1075
[[2.4517565 2.5078802 3.9094186]] - model q_values
[[2.4517565 2.5078802 3.9094186]] - step_model q_values
[[2.4517565 2.5078802 3.9094186]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1076
[[1.7700114 2.3517292 3.428778 ]] - model q_values
[[1.7700114 2.3517292 3.428778 ]] - step_model q_values
[[1.7700114 2.3517292 3.428778 ]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1077
[[0.58552134 2.1045809  4.5251217 ]] - model q_values
[[0.58552134 2.1045809  4.5251217 ]] - step_model q_values
[[0.58552134 2.1045809  4.5251217 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1078
[[0.95599294 2.0664692  4.8444014 ]] - model q_values
[[0.95599294 2.0664692  4.8444014 ]] - step_model q_values
[[0.95599294 2.0664692  4.8444014 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1079
[[2.5116456 2.584446  3.8878655]] - model q_values
[[2.5116456 2.584446  3.8878655]] - step_model q_values
[[2.5116456 2.584446  3.8878655]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1080
[[1.8157208 2.4122384 3.37623  ]] - model q_values
[[1.8157208 2.4122384 3.37623  ]] - step_model q_values
[[1.8157208 2.4122384 3.37623  ]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1081
[[0.61643815 2.150397   4.461681  ]] - model q_values
[[0.61643815 2.150397   4.461681  ]] - step_model q_values
[[0.61643815 2.150397   4.461681  ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1082
[[0.99003816 2.117011   4.7999234 ]] - model q_values
[[0.99003816 2.117011   4.7999234 ]] - step_model q_values
[[0.99003816 2.117011   4.7999234 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1083
[[2.5584848 2.6567326 3.8644114]] - model q_values
[[2.5584848 2.6567326 3.8644114]] - step_model q_values
[[2.5584848 2.6567326 3.8644114]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1084
[[1.8554893 2.4767802 3.3322265]] - model q_values
[[1.8554893 2.4767802 3.3322265]] - step_model q_values
[[1.8554893 2.4767802 3.3322265]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1085
[[0.6464931 2.1993682 4.408722 ]] - model q_values
[[0.6464931 2.1993682 4.408722 ]] - step_model q_values
[[0.6464931 2.1993682 4.408722 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1086
[[1.0295111 2.1734028 4.7716403]] - model q_values
[[1.0295111 2.1734028 4.7716403]] - step_model q_values
[[1.0295111 2.1734028 4.7716403]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1087
[[2.614431 2.73348  3.866051]] - model q_values
[[2.614431 2.73348  3.866051]] - step_model q_values
[[2.614431 2.73348  3.866051]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1088
[[1.9107656 2.5473974 3.32445  ]] - model q_values
[[1.9107656 2.5473974 3.32445  ]] - step_model q_values
[[1.9107656 2.5473974 3.32445  ]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1089
[[0.6931224 2.2537768 4.399867 ]] - model q_values
[[0.6931224 2.2537768 4.399867 ]] - step_model q_values
[[0.6931224 2.2537768 4.399867 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1090
[[1.0863335 2.234879  4.783044 ]] - model q_values
[[1.0863335 2.234879  4.783044 ]] - step_model q_values
[[1.0863335 2.234879  4.783044 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1091
[[2.6880674 2.8158374 3.8984036]] - model q_values
[[2.6880674 2.8158374 3.8984036]] - step_model q_values
[[2.6880674 2.8158374 3.8984036]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1092
[[1.9776287 2.62522   3.3349257]] - model q_values
[[1.9776287 2.62522   3.3349257]] - step_model q_values
[[1.9776287 2.62522   3.3349257]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1093
[[0.74169207 2.3137608  4.3887286 ]] - model q_values
[[0.74169207 2.3137608  4.3887286 ]] - step_model q_values
[[0.74169207 2.3137608  4.3887286 ]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1094
[[1.1385684 2.2990007 4.7832384]] - model q_values
[[1.1385684 2.2990007 4.7832384]] - step_model q_values
[[1.1385684 2.2990007 4.7832384]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1095
[[2.7516177 2.895031  3.910235 ]] - model q_values
[[2.7516177 2.895031  3.910235 ]] - step_model q_values
[[2.7516177 2.895031  3.910235 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1096
[[2.0339496 2.6984818 3.3279757]] - model q_values
[[2.0339496 2.6984818 3.3279757]] - step_model q_values
[[2.0339496 2.6984818 3.3279757]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1097
[[0.7879987 2.373691  4.3850036]] - model q_values
[[0.7879987 2.373691  4.3850036]] - step_model q_values
[[0.7879987 2.373691  4.3850036]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1098
[[1.1922425 2.3630986 4.8007426]] - model q_values
[[1.1922425 2.3630986 4.8007426]] - step_model q_values
[[1.1922425 2.3630986 4.8007426]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1099
[[2.821101  2.9751341 3.9481094]] - model q_values
[[2.821101  2.9751341 3.9481094]] - step_model q_values
[[2.821101  2.9751341 3.9481094]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1100
[[2.099515  2.772714  3.3563728]] - model q_values
[[2.099515  2.772714  3.3563728]] - step_model q_values
[[2.099515  2.772714  3.3563728]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1101
[[0.8423765 2.4340656 4.4014077]] - model q_values
[[0.8423765 2.4340656 4.4014077]] - step_model q_values
[[0.8423765 2.4340656 4.4014077]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1102
[[1.251996  2.4264753 4.826591 ]] - model q_values
[[1.251996  2.4264753 4.826591 ]] - step_model q_values
[[1.251996  2.4264753 4.826591 ]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1103
[[2.8927681 3.049609  3.9837022]] - model q_values
[[2.8927681 3.049609  3.9837022]] - step_model q_values
[[2.8927681 3.049609  3.9837022]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1104
[[2.1677067 2.8419523 3.3679225]] - model q_values
[[2.1677067 2.8419523 3.3679225]] - step_model q_values
[[2.1677067 2.8419523 3.3679225]] - double_policy q_values
[[1.2305678 1.3680463 5.2540035]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1105
[[0.894693  2.4867084 4.3908105]] - model q_values
[[0.894693  2.4867084 4.3908105]] - step_model q_values
[[0.894693  2.4867084 4.3908105]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1106
[[1.3125688 2.490273  4.8196545]] - model q_values
[[1.3125688 2.490273  4.8196545]] - step_model q_values
[[1.3125688 2.490273  4.8196545]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  5.220061

num_timesteps:  1107
[[1.2982392 2.8078623 5.338319 ]] - model q_values
[[1.2982392 2.8078623 5.338319 ]] - step_model q_values
[[1.2982392 2.8078623 5.338319 ]] - double_policy q_values
[[0.4724431 1.5731843 5.5356407]] - target_policy q_values
Training
_max_priority:  5.2255373

num_timesteps:  1108
[[3.463715  3.4867468 4.025069 ]] - model q_values
[[3.463715  3.4867468 4.025069 ]] - step_model q_values
[[3.463715  3.4867468 4.025069 ]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.2255373

num_timesteps:  1109
[[2.3773563 3.1271887 3.1516387]] - model q_values
[[2.3773563 3.1271887 3.1516387]] - step_model q_values
[[2.3773563 3.1271887 3.1516387]] - double_policy q_values
[[1.3282919 1.5293927 5.1568766]] - target_policy q_values
Training
_max_priority:  5.395708

num_timesteps:  1110
[[0.491068  2.5941257 4.2483234]] - model q_values
[[0.491068  2.5941257 4.2483234]] - step_model q_values
[[0.491068  2.5941257 4.2483234]] - double_policy q_values
[[-0.8755654   0.80764985  3.4158368 ]] - target_policy q_values
Training
_max_priority:  5.395708

num_timesteps:  1111
[[1.3473672 2.8446147 5.26046  ]] - model q_values
[[1.3473672 2.8446147 5.26046  ]] - step_model q_values
[[1.3473672 2.8446147 5.26046  ]] - double_policy q_values
[[0.4724431 1.5731843 5.5356407]] - target_policy q_values
Training
_max_priority:  5.395708

num_timesteps:  1112
[[3.4937277 3.5205858 3.9258685]] - model q_values
[[3.4937277 3.5205858 3.9258685]] - step_model q_values
[[3.4937277 3.5205858 3.9258685]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.395708

num_timesteps:  1113
[[2.4053142 3.1554322 3.0310256]] - model q_values
[[2.4053142 3.1554322 3.0310256]] - step_model q_values
[[2.4053142 3.1554322 3.0310256]] - double_policy q_values
[[1.3282919 1.5293927 5.1568766]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1114
[[3.5036964 3.5360582 3.8768284]] - model q_values
[[3.5036964 3.5360582 3.8768284]] - step_model q_values
[[3.5036964 3.5360582 3.8768284]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1115
[[2.4124465 3.1665604 2.9569466]] - model q_values
[[2.4124465 3.1665604 2.9569466]] - step_model q_values
[[2.4124465 3.1665604 2.9569466]] - double_policy q_values
[[1.3282919 1.5293927 5.1568766]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1116
[[3.5079272 3.5481975 3.8092558]] - model q_values
[[3.5079272 3.5481975 3.8092558]] - step_model q_values
[[3.5079272 3.5481975 3.8092558]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1117
[[2.426135 3.180998 2.902999]] - model q_values
[[2.426135 3.180998 2.902999]] - step_model q_values
[[2.426135 3.180998 2.902999]] - double_policy q_values
[[1.3282919 1.5293927 5.1568766]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1118
[[3.5242054 3.5659485 3.7816854]] - model q_values
[[3.5242054 3.5659485 3.7816854]] - step_model q_values
[[3.5242054 3.5659485 3.7816854]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1119
[[2.452918  3.205129  2.8995337]] - model q_values
[[2.452918  3.205129  2.8995337]] - step_model q_values
[[2.452918  3.205129  2.8995337]] - double_policy q_values
[[1.3282919 1.5293927 5.1568766]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1120
[[3.5466783 3.5884569 3.7775095]] - model q_values
[[3.5466783 3.5884569 3.7775095]] - step_model q_values
[[3.5466783 3.5884569 3.7775095]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1121
[[2.4788892 3.2277567 2.8911207]] - model q_values
[[2.4788892 3.2277567 2.8911207]] - step_model q_values
[[2.4788892 3.2277567 2.8911207]] - double_policy q_values
[[1.3282919 1.5293927 5.1568766]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1122
[[3.5686836 3.6065774 3.7662973]] - model q_values
[[3.5686836 3.6065774 3.7662973]] - step_model q_values
[[3.5686836 3.6065774 3.7662973]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1123
[[2.5087938 3.251504  2.8887217]] - model q_values
[[2.5087938 3.251504  2.8887217]] - step_model q_values
[[2.5087938 3.251504  2.8887217]] - double_policy q_values
[[1.3282919 1.5293927 5.1568766]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1124
[[3.5777743 3.6150894 3.7235467]] - model q_values
[[3.5777743 3.6150894 3.7235467]] - step_model q_values
[[3.5777743 3.6150894 3.7235467]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1125
[[2.5226023 3.2614865 2.840309 ]] - model q_values
[[2.5226023 3.2614865 2.840309 ]] - step_model q_values
[[2.5226023 3.2614865 2.840309 ]] - double_policy q_values
[[1.3282919 1.5293927 5.1568766]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1126
[[3.5762906 3.620626  3.659132 ]] - model q_values
[[3.5762906 3.620626  3.659132 ]] - step_model q_values
[[3.5762906 3.620626  3.659132 ]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1127
[[2.535549  3.2784986 2.7892158]] - model q_values
[[2.535549  3.2784986 2.7892158]] - step_model q_values
[[2.535549  3.2784986 2.7892158]] - double_policy q_values
[[1.3282919 1.5293927 5.1568766]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1128
[[3.5812356 3.6325624 3.610089 ]] - model q_values
[[3.5812356 3.6325624 3.610089 ]] - step_model q_values
[[3.5812356 3.6325624 3.610089 ]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1129
[[1.5599269 2.9957151 5.0805306]] - model q_values
[[1.5599269 2.9957151 5.0805306]] - step_model q_values
[[1.5599269 2.9957151 5.0805306]] - double_policy q_values
[[0.4724431 1.5731843 5.5356407]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1130
[[3.5881603 3.6435091 3.5787222]] - model q_values
[[3.5881603 3.6435091 3.5787222]] - step_model q_values
[[3.5881603 3.6435091 3.5787222]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1131
[[1.5687414 2.9985802 5.05728  ]] - model q_values
[[1.5687414 2.9985802 5.05728  ]] - step_model q_values
[[1.5687414 2.9985802 5.05728  ]] - double_policy q_values
[[0.4724431 1.5731843 5.5356407]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1132
[[3.5855448 3.6443436 3.5351753]] - model q_values
[[3.5855448 3.6443436 3.5351753]] - step_model q_values
[[3.5855448 3.6443436 3.5351753]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1133
[[1.5740637 2.9942794 5.04253  ]] - model q_values
[[1.5740637 2.9942794 5.04253  ]] - step_model q_values
[[1.5740637 2.9942794 5.04253  ]] - double_policy q_values
[[0.4724431 1.5731843 5.5356407]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1134
[[3.587273  3.6424005 3.5039177]] - model q_values
[[3.587273  3.6424005 3.5039177]] - step_model q_values
[[3.587273  3.6424005 3.5039177]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1135
[[1.5755093 2.9830186 5.01664  ]] - model q_values
[[1.5755093 2.9830186 5.01664  ]] - step_model q_values
[[1.5755093 2.9830186 5.01664  ]] - double_policy q_values
[[0.4724431 1.5731843 5.5356407]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1136
[[3.5905387 3.6410265 3.4650407]] - model q_values
[[3.5905387 3.6410265 3.4650407]] - step_model q_values
[[3.5905387 3.6410265 3.4650407]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1137
[[1.5783157 2.9686878 4.991887 ]] - model q_values
[[1.5783157 2.9686878 4.991887 ]] - step_model q_values
[[1.5783157 2.9686878 4.991887 ]] - double_policy q_values
[[0.4724431 1.5731843 5.5356407]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1138
[[3.5959907 3.6289983 3.4313447]] - model q_values
[[3.5959907 3.6289983 3.4313447]] - step_model q_values
[[3.5959907 3.6289983 3.4313447]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1139
[[1.5812244 2.9484823 4.965181 ]] - model q_values
[[1.5812244 2.9484823 4.965181 ]] - step_model q_values
[[1.5812244 2.9484823 4.965181 ]] - double_policy q_values
[[0.4724431 1.5731843 5.5356407]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1140
[[3.6040823 3.6174753 3.4034176]] - model q_values
[[3.6040823 3.6174753 3.4034176]] - step_model q_values
[[3.6040823 3.6174753 3.4034176]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1141
[[1.5894246 2.9339743 4.9494133]] - model q_values
[[1.5894246 2.9339743 4.9494133]] - step_model q_values
[[1.5894246 2.9339743 4.9494133]] - double_policy q_values
[[0.4724431 1.5731843 5.5356407]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1142
[[3.6126106 3.608335  3.3842025]] - model q_values
[[3.6126106 3.608335  3.3842025]] - step_model q_values
[[3.6126106 3.608335  3.3842025]] - double_policy q_values
[[2.6515713 2.0235364 6.285151 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1143
[[2.1185572 2.2999625 3.2088666]] - model q_values
[[2.1185572 2.2999625 3.2088666]] - step_model q_values
[[2.1185572 2.2999625 3.2088666]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1144
[[4.8605814 5.179964  1.0689178]] - model q_values
[[4.8605814 5.179964  1.0689178]] - step_model q_values
[[4.8605814 5.179964  1.0689178]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1145
[[2.1351955 2.3065228 3.1956   ]] - model q_values
[[2.1351955 2.3065228 3.1956   ]] - step_model q_values
[[2.1351955 2.3065228 3.1956   ]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1146
[[4.8957896 5.1958175 1.0875368]] - model q_values
[[4.8957896 5.1958175 1.0875368]] - step_model q_values
[[4.8957896 5.1958175 1.0875368]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1147
[[2.1703556 2.326428  3.1876402]] - model q_values
[[2.1703556 2.326428  3.1876402]] - step_model q_values
[[2.1703556 2.326428  3.1876402]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1148
[[4.937249  5.215437  1.1120896]] - model q_values
[[4.937249  5.215437  1.1120896]] - step_model q_values
[[4.937249  5.215437  1.1120896]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1149
[[2.209665  2.3478198 3.186676 ]] - model q_values
[[2.209665  2.3478198 3.186676 ]] - step_model q_values
[[2.209665  2.3478198 3.186676 ]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1150
[[4.9791245 5.2286844 1.1479087]] - model q_values
[[4.9791245 5.2286844 1.1479087]] - step_model q_values
[[4.9791245 5.2286844 1.1479087]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1151
[[2.24289   2.3615146 3.181715 ]] - model q_values
[[2.24289   2.3615146 3.181715 ]] - step_model q_values
[[2.24289   2.3615146 3.181715 ]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1152
[[5.01279   5.2349463 1.1703467]] - model q_values
[[5.01279   5.2349463 1.1703467]] - step_model q_values
[[5.01279   5.2349463 1.1703467]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1153
[[2.26889   2.3722916 3.166159 ]] - model q_values
[[2.26889   2.3722916 3.166159 ]] - step_model q_values
[[2.26889   2.3722916 3.166159 ]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1154
[[5.0318937 5.2346983 1.167872 ]] - model q_values
[[5.0318937 5.2346983 1.167872 ]] - step_model q_values
[[5.0318937 5.2346983 1.167872 ]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1155
[[2.284191  2.3795583 3.121919 ]] - model q_values
[[2.284191  2.3795583 3.121919 ]] - step_model q_values
[[2.284191  2.3795583 3.121919 ]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1156
[[5.038949  5.2280774 1.1448798]] - model q_values
[[5.038949  5.2280774 1.1448798]] - step_model q_values
[[5.038949  5.2280774 1.1448798]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1157
[[2.294009  2.385388  3.0661361]] - model q_values
[[2.294009  2.385388  3.0661361]] - step_model q_values
[[2.294009  2.385388  3.0661361]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1158
[[5.0428214 5.2204695 1.1165445]] - model q_values
[[5.0428214 5.2204695 1.1165445]] - step_model q_values
[[5.0428214 5.2204695 1.1165445]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1159
[[2.302764 2.391244 3.001347]] - model q_values
[[2.302764 2.391244 3.001347]] - step_model q_values
[[2.302764 2.391244 3.001347]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1160
[[5.0427322 5.2085695 1.0839434]] - model q_values
[[5.0427322 5.2085695 1.0839434]] - step_model q_values
[[5.0427322 5.2085695 1.0839434]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1161
[[2.3128185 2.3966825 2.9323301]] - model q_values
[[2.3128185 2.3966825 2.9323301]] - step_model q_values
[[2.3128185 2.3966825 2.9323301]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1162
[[5.043866  5.1885176 1.0586953]] - model q_values
[[5.043866  5.1885176 1.0586953]] - step_model q_values
[[5.043866  5.1885176 1.0586953]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1163
[[2.3303077 2.4088886 2.8698502]] - model q_values
[[2.3303077 2.4088886 2.8698502]] - step_model q_values
[[2.3303077 2.4088886 2.8698502]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1164
[[5.0430307 5.16654   1.0321858]] - model q_values
[[5.0430307 5.16654   1.0321858]] - step_model q_values
[[5.0430307 5.16654   1.0321858]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1165
[[2.3397655 2.4127035 2.7968228]] - model q_values
[[2.3397655 2.4127035 2.7968228]] - step_model q_values
[[2.3397655 2.4127035 2.7968228]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1166
[[5.0311213 5.1293535 0.9842334]] - model q_values
[[5.0311213 5.1293535 0.9842334]] - step_model q_values
[[5.0311213 5.1293535 0.9842334]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1167
[[2.344534  2.409822  2.7205825]] - model q_values
[[2.344534  2.409822  2.7205825]] - step_model q_values
[[2.344534  2.409822  2.7205825]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1168
[[5.0197563 5.0891533 0.9366126]] - model q_values
[[5.0197563 5.0891533 0.9366126]] - step_model q_values
[[5.0197563 5.0891533 0.9366126]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1169
[[2.343554  2.398479  2.6303353]] - model q_values
[[2.343554  2.398479  2.6303353]] - step_model q_values
[[2.343554  2.398479  2.6303353]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1170
[[5.000687   5.0329967  0.86793804]] - model q_values
[[5.000687   5.0329967  0.86793804]] - step_model q_values
[[5.000687   5.0329967  0.86793804]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1171
[[2.3440177 2.3831334 2.53885  ]] - model q_values
[[2.3440177 2.3831334 2.53885  ]] - step_model q_values
[[2.3440177 2.3831334 2.53885  ]] - double_policy q_values
[[1.7062368 1.6804825 5.330859 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1172
[[4.9874063 4.981483  0.809304 ]] - model q_values
[[4.9874063 4.981483  0.809304 ]] - step_model q_values
[[4.9874063 4.981483  0.809304 ]] - double_policy q_values
[[3.928553  3.4780936 4.060752 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1173
[[5.1518426  5.150404   0.68575406]] - model q_values
[[5.1518426  5.150404   0.68575406]] - step_model q_values
[[5.1518426  5.150404   0.68575406]] - double_policy q_values
[[4.139015  3.660053  3.8543446]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1174
[[2.90236  3.149671 2.516968]] - model q_values
[[2.90236  3.149671 2.516968]] - step_model q_values
[[2.90236  3.149671 2.516968]] - double_policy q_values
[[2.0879126 2.179103  5.966529 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1175
[[3.1967657 3.0247304 3.004378 ]] - model q_values
[[3.1967657 3.0247304 3.004378 ]] - step_model q_values
[[3.1967657 3.0247304 3.004378 ]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1176
[[3.1555963 3.007017  3.296606 ]] - model q_values
[[3.1555963 3.007017  3.296606 ]] - step_model q_values
[[3.1555963 3.007017  3.296606 ]] - double_policy q_values
[[1.9354621 1.6924827 5.7600517]] - target_policy q_values
Training
_max_priority:  5.5354795

num_timesteps:  1177
[[2.973167  2.845636  2.3413851]] - model q_values
[[2.973167  2.845636  2.3413851]] - step_model q_values
[[2.973167  2.845636  2.3413851]] - double_policy q_values
[[1.7030478 1.4251608 5.880868 ]] - target_policy q_values
Training
_max_priority:  44.84742

num_timesteps:  1178
[[2.818069  2.5939386 2.4578319]] - model q_values
[[2.818069  2.5939386 2.4578319]] - step_model q_values
[[2.818069  2.5939386 2.4578319]] - double_policy q_values
[[1.5225469 1.189048  5.9127026]] - target_policy q_values
Training
_max_priority:  44.84742

num_timesteps:  1179
[[2.7176468 2.5627484 2.7133586]] - model q_values
[[2.7176468 2.5627484 2.7133586]] - step_model q_values
[[2.7176468 2.5627484 2.7133586]] - double_policy q_values
[[1.4322425 1.2111766 5.8347464]] - target_policy q_values
Training
_max_priority:  44.84742

num_timesteps:  1180
[[-0.20023456  0.4548522  -0.0610367 ]] - model q_values
[[-0.20023456  0.4548522  -0.0610367 ]] - step_model q_values
[[-0.20023456  0.4548522  -0.0610367 ]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.84742

num_timesteps:  1181
[[1.7716914 2.3680182 3.8454792]] - model q_values
[[1.7716914 2.3680182 3.8454792]] - step_model q_values
[[1.7716914 2.3680182 3.8454792]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.84742

num_timesteps:  1182
[[-0.19519873  0.45209986 -0.11753312]] - model q_values
[[-0.19519873  0.45209986 -0.11753312]] - step_model q_values
[[-0.19519873  0.45209986 -0.11753312]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.84742

num_timesteps:  1183
[[1.748083  2.3373666 3.7312462]] - model q_values
[[1.748083  2.3373666 3.7312462]] - step_model q_values
[[1.748083  2.3373666 3.7312462]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.85412

num_timesteps:  1184
[[-0.1932292   0.45199895 -0.21768531]] - model q_values
[[-0.1932292   0.45199895 -0.21768531]] - step_model q_values
[[-0.1932292   0.45199895 -0.21768531]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.85412

num_timesteps:  1185
[[1.7215357 2.3051796 3.5966716]] - model q_values
[[1.7215357 2.3051796 3.5966716]] - step_model q_values
[[1.7215357 2.3051796 3.5966716]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.85412

num_timesteps:  1186
[[-0.18895993  0.4527827  -0.32250538]] - model q_values
[[-0.18895993  0.4527827  -0.32250538]] - step_model q_values
[[-0.18895993  0.4527827  -0.32250538]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.85412

num_timesteps:  1187
[[1.7054617 2.28295   3.4938147]] - model q_values
[[1.7054617 2.28295   3.4938147]] - step_model q_values
[[1.7054617 2.28295   3.4938147]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1188
[[-0.17992434  0.4561441  -0.38427627]] - model q_values
[[-0.17992434  0.4561441  -0.38427627]] - step_model q_values
[[-0.17992434  0.4561441  -0.38427627]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1189
[[1.7007422 2.269138  3.434347 ]] - model q_values
[[1.7007422 2.269138  3.434347 ]] - step_model q_values
[[1.7007422 2.269138  3.434347 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1190
[[-0.16972737  0.4571958  -0.4184638 ]] - model q_values
[[-0.16972737  0.4571958  -0.4184638 ]] - step_model q_values
[[-0.16972737  0.4571958  -0.4184638 ]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1191
[[1.6970067 2.251496  3.3796756]] - model q_values
[[1.6970067 2.251496  3.3796756]] - step_model q_values
[[1.6970067 2.251496  3.3796756]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1192
[[-0.15716755  0.45859182 -0.45406824]] - model q_values
[[-0.15716755  0.45859182 -0.45406824]] - step_model q_values
[[-0.15716755  0.45859182 -0.45406824]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1193
[[1.6988394 2.2409117 3.3452272]] - model q_values
[[1.6988394 2.2409117 3.3452272]] - step_model q_values
[[1.6988394 2.2409117 3.3452272]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1194
[[-0.14668943  0.46852145 -0.4902119 ]] - model q_values
[[-0.14668943  0.46852145 -0.4902119 ]] - step_model q_values
[[-0.14668943  0.46852145 -0.4902119 ]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1195
[[1.7013655 2.2365785 3.2675996]] - model q_values
[[1.7013655 2.2365785 3.2675996]] - step_model q_values
[[1.7013655 2.2365785 3.2675996]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1196
[[-0.14029342  0.49031132 -0.5536251 ]] - model q_values
[[-0.14029342  0.49031132 -0.5536251 ]] - step_model q_values
[[-0.14029342  0.49031132 -0.5536251 ]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1197
[[1.7089787 2.241588  3.1591775]] - model q_values
[[1.7089787 2.241588  3.1591775]] - step_model q_values
[[1.7089787 2.241588  3.1591775]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1198
[[-0.13226369  0.50723934 -0.59686905]] - model q_values
[[-0.13226369  0.50723934 -0.59686905]] - step_model q_values
[[-0.13226369  0.50723934 -0.59686905]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1199
[[1.7263006 2.2512918 3.099829 ]] - model q_values
[[1.7263006 2.2512918 3.099829 ]] - step_model q_values
[[1.7263006 2.2512918 3.099829 ]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1200
[[-0.11875518  0.52420586 -0.59836787]] - model q_values
[[-0.11875518  0.52420586 -0.59836787]] - step_model q_values
[[-0.11875518  0.52420586 -0.59836787]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1201
[[1.7472341 2.263289  3.0794559]] - model q_values
[[1.7472341 2.263289  3.0794559]] - step_model q_values
[[1.7472341 2.263289  3.0794559]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1202
[[-0.10208158  0.5347623  -0.5627269 ]] - model q_values
[[-0.10208158  0.5347623  -0.5627269 ]] - step_model q_values
[[-0.10208158  0.5347623  -0.5627269 ]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1203
[[1.7677789 2.275536  3.0545104]] - model q_values
[[1.7677789 2.275536  3.0545104]] - step_model q_values
[[1.7677789 2.275536  3.0545104]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1204
[[-0.08675532  0.5490998  -0.55669713]] - model q_values
[[-0.08675532  0.5490998  -0.55669713]] - step_model q_values
[[-0.08675532  0.5490998  -0.55669713]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1205
[[1.7835345 2.2790418 2.9971366]] - model q_values
[[1.7835345 2.2790418 2.9971366]] - step_model q_values
[[1.7835345 2.2790418 2.9971366]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1206
[[-0.07226081  0.5695296  -0.57897645]] - model q_values
[[-0.07226081  0.5695296  -0.57897645]] - step_model q_values
[[-0.07226081  0.5695296  -0.57897645]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1207
[[1.7906916 2.2808943 2.9136474]] - model q_values
[[1.7906916 2.2808943 2.9136474]] - step_model q_values
[[1.7906916 2.2808943 2.9136474]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1208
[[-0.06413557  0.58921665 -0.6003626 ]] - model q_values
[[-0.06413557  0.58921665 -0.6003626 ]] - step_model q_values
[[-0.06413557  0.58921665 -0.6003626 ]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1209
[[1.7884135 2.2834058 2.8348632]] - model q_values
[[1.7884135 2.2834058 2.8348632]] - step_model q_values
[[1.7884135 2.2834058 2.8348632]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1210
[[-0.0612295  0.60951   -0.6082105]] - model q_values
[[-0.0612295  0.60951   -0.6082105]] - step_model q_values
[[-0.0612295  0.60951   -0.6082105]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1211
[[1.7859381 2.2864804 2.7416234]] - model q_values
[[1.7859381 2.2864804 2.7416234]] - step_model q_values
[[1.7859381 2.2864804 2.7416234]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1212
[[-0.05564273  0.62467873 -0.62934923]] - model q_values
[[-0.05564273  0.62467873 -0.62934923]] - step_model q_values
[[-0.05564273  0.62467873 -0.62934923]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1213
[[1.7730622 2.2816098 2.5891912]] - model q_values
[[1.7730622 2.2816098 2.5891912]] - step_model q_values
[[1.7730622 2.2816098 2.5891912]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1214
[[-0.05342721  0.65017253 -0.6938851 ]] - model q_values
[[-0.05342721  0.65017253 -0.6938851 ]] - step_model q_values
[[-0.05342721  0.65017253 -0.6938851 ]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1215
[[1.749275  2.2743487 2.3729105]] - model q_values
[[1.749275  2.2743487 2.3729105]] - step_model q_values
[[1.749275  2.2743487 2.3729105]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1216
[[-0.04950362  0.6777641  -0.78551286]] - model q_values
[[-0.04950362  0.6777641  -0.78551286]] - step_model q_values
[[-0.04950362  0.6777641  -0.78551286]] - double_policy q_values
[[-0.08233762 -0.04555011  5.4234905 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1217
[[1.726893  2.2676601 2.1269052]] - model q_values
[[1.726893  2.2676601 2.1269052]] - step_model q_values
[[1.726893  2.2676601 2.1269052]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1218
[[1.7632022 2.4853017 2.5550487]] - model q_values
[[1.7632022 2.4853017 2.5550487]] - step_model q_values
[[1.7632022 2.4853017 2.5550487]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1219
[[1.704786  2.262029  1.8649836]] - model q_values
[[1.704786  2.262029  1.8649836]] - step_model q_values
[[1.704786  2.262029  1.8649836]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1220
[[1.7313621 2.4587817 2.3073437]] - model q_values
[[1.7313621 2.4587817 2.3073437]] - step_model q_values
[[1.7313621 2.4587817 2.3073437]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1221
[[1.6805675 2.260505  1.5766109]] - model q_values
[[1.6805675 2.260505  1.5766109]] - step_model q_values
[[1.6805675 2.260505  1.5766109]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1222
[[1.6904498 2.424472  1.9944607]] - model q_values
[[1.6904498 2.424472  1.9944607]] - step_model q_values
[[1.6904498 2.424472  1.9944607]] - double_policy q_values
[[0.08995771 0.96927834 4.3532004 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1223
[[3.4990196 2.0388308 2.0458517]] - model q_values
[[3.4990196 2.0388308 2.0458517]] - step_model q_values
[[3.4990196 2.0388308 2.0458517]] - double_policy q_values
[[ 0.52193147 -0.33670187  2.4006045 ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1224
[[2.1627653  2.2511244  0.51717484]] - model q_values
[[2.1627653  2.2511244  0.51717484]] - step_model q_values
[[2.1627653  2.2511244  0.51717484]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1225
[[2.1730785  2.483805   0.48122787]] - model q_values
[[2.1730785  2.483805   0.48122787]] - step_model q_values
[[2.1730785  2.483805   0.48122787]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1226
[[1.7802026 2.2535856 0.7411732]] - model q_values
[[1.7802026 2.2535856 0.7411732]] - step_model q_values
[[1.7802026 2.2535856 0.7411732]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  44.874146

num_timesteps:  1227
[[1.8801901  2.279355   0.54024065]] - model q_values
[[1.8801901  2.279355   0.54024065]] - step_model q_values
[[1.8801901  2.279355   0.54024065]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  45.047043

num_timesteps:  1228
[[ 2.0893364   2.2884247  -0.09309649]] - model q_values
[[ 2.0893364   2.2884247  -0.09309649]] - step_model q_values
[[ 2.0893364   2.2884247  -0.09309649]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  45.047043

num_timesteps:  1229
[[ 2.1146164  2.5343091 -0.1378038]] - model q_values
[[ 2.1146164  2.5343091 -0.1378038]] - step_model q_values
[[ 2.1146164  2.5343091 -0.1378038]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  45.047043

num_timesteps:  1230
[[1.7422678  2.3029766  0.12637949]] - model q_values
[[1.7422678  2.3029766  0.12637949]] - step_model q_values
[[1.7422678  2.3029766  0.12637949]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  45.047043

num_timesteps:  1231
[[ 1.7640045   2.281968   -0.00653148]] - model q_values
[[ 1.7640045   2.281968   -0.00653148]] - step_model q_values
[[ 1.7640045   2.281968   -0.00653148]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  45.304882

num_timesteps:  1232
[[ 1.8621054   2.280456   -0.39939272]] - model q_values
[[ 1.8621054   2.280456   -0.39939272]] - step_model q_values
[[ 1.8621054   2.280456   -0.39939272]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  45.386665

num_timesteps:  1233
[[ 1.8873556  2.5022788 -0.3404504]] - model q_values
[[ 1.8873556  2.5022788 -0.3404504]] - step_model q_values
[[ 1.8873556  2.5022788 -0.3404504]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  45.468075

num_timesteps:  1234
[[ 1.5473349   2.2487202  -0.01291823]] - model q_values
[[ 1.5473349   2.2487202  -0.01291823]] - step_model q_values
[[ 1.5473349   2.2487202  -0.01291823]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  45.468075

num_timesteps:  1235
[[ 1.5639076   2.188837   -0.08507717]] - model q_values
[[ 1.5639076   2.188837   -0.08507717]] - step_model q_values
[[ 1.5639076   2.188837   -0.08507717]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  45.468075

num_timesteps:  1236
[[ 1.5470068  2.2234144 -0.3488767]] - model q_values
[[ 1.5470068  2.2234144 -0.3488767]] - step_model q_values
[[ 1.5470068  2.2234144 -0.3488767]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  45.468075

num_timesteps:  1237
[[ 1.6006137   2.4209156  -0.26698315]] - model q_values
[[ 1.6006137   2.4209156  -0.26698315]] - step_model q_values
[[ 1.6006137   2.4209156  -0.26698315]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  45.468075

num_timesteps:  1238
[[1.2933646 2.1506016 0.0645963]] - model q_values
[[1.2933646 2.1506016 0.0645963]] - step_model q_values
[[1.2933646 2.1506016 0.0645963]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  45.468075

num_timesteps:  1239
[[1.3009198  2.0500693  0.03280103]] - model q_values
[[1.3009198  2.0500693  0.03280103]] - step_model q_values
[[1.3009198  2.0500693  0.03280103]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  45.468075

num_timesteps:  1240
[[ 1.252147    2.0649629  -0.16126895]] - model q_values
[[ 1.252147    2.0649629  -0.16126895]] - step_model q_values
[[ 1.252147    2.0649629  -0.16126895]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  46.025116

num_timesteps:  1241
[[ 1.3255962   2.2541184  -0.08903587]] - model q_values
[[ 1.3255962   2.2541184  -0.08903587]] - step_model q_values
[[ 1.3255962   2.2541184  -0.08903587]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  46.095764

num_timesteps:  1242
[[1.0489099  2.002902   0.19097656]] - model q_values
[[1.0489099  2.002902   0.19097656]] - step_model q_values
[[1.0489099  2.002902   0.19097656]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  46.16215

num_timesteps:  1243
[[1.0647281  1.8926629  0.14249945]] - model q_values
[[1.0647281  1.8926629  0.14249945]] - step_model q_values
[[1.0647281  1.8926629  0.14249945]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  46.22519

num_timesteps:  1244
[[1.01031    1.8807689  0.01403111]] - model q_values
[[1.01031    1.8807689  0.01403111]] - step_model q_values
[[1.01031    1.8807689  0.01403111]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  46.22519

num_timesteps:  1245
[[1.1225324  2.0698686  0.06787169]] - model q_values
[[1.1225324  2.0698686  0.06787169]] - step_model q_values
[[1.1225324  2.0698686  0.06787169]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  46.22519

num_timesteps:  1246
[[0.894148  1.8193135 0.2991395]] - model q_values
[[0.894148  1.8193135 0.2991395]] - step_model q_values
[[0.894148  1.8193135 0.2991395]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  46.22519

num_timesteps:  1247
[[0.9437521  1.6771414  0.20794135]] - model q_values
[[0.9437521  1.6771414  0.20794135]] - step_model q_values
[[0.9437521  1.6771414  0.20794135]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  46.368073

num_timesteps:  1248
[[0.8941538  1.6402295  0.10275048]] - model q_values
[[0.8941538  1.6402295  0.10275048]] - step_model q_values
[[0.8941538  1.6402295  0.10275048]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  46.40143

num_timesteps:  1249
[[1.0403538  1.836364   0.09184569]] - model q_values
[[1.0403538  1.836364   0.09184569]] - step_model q_values
[[1.0403538  1.836364   0.09184569]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  46.40143

num_timesteps:  1250
[[0.8341795 1.61199   0.261104 ]] - model q_values
[[0.8341795 1.61199   0.261104 ]] - step_model q_values
[[0.8341795 1.61199   0.261104 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  46.40143

num_timesteps:  1251
[[0.898784   1.4625417  0.12326705]] - model q_values
[[0.898784   1.4625417  0.12326705]] - step_model q_values
[[0.898784   1.4625417  0.12326705]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  46.40143

num_timesteps:  1252
[[0.86884034 1.4018583  0.02099788]] - model q_values
[[0.86884034 1.4018583  0.02099788]] - step_model q_values
[[0.86884034 1.4018583  0.02099788]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  46.441605

num_timesteps:  1253
[[ 1.0248221   1.604357   -0.01144141]] - model q_values
[[ 1.0248221   1.604357   -0.01144141]] - step_model q_values
[[ 1.0248221   1.604357   -0.01144141]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  46.441605

num_timesteps:  1254
[[ 0.8405458   1.267462   -0.01300949]] - model q_values
[[ 0.8405458   1.267462   -0.01300949]] - step_model q_values
[[ 0.8405458   1.267462   -0.01300949]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  46.441605

num_timesteps:  1255
[[ 0.9933252   1.4797158  -0.01760209]] - model q_values
[[ 0.9933252   1.4797158  -0.01760209]] - step_model q_values
[[ 0.9933252   1.4797158  -0.01760209]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  46.441605

num_timesteps:  1256
[[0.7796469  1.2719998  0.16925651]] - model q_values
[[0.7796469  1.2719998  0.16925651]] - step_model q_values
[[0.7796469  1.2719998  0.16925651]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  46.535442

num_timesteps:  1257
[[0.75599885 1.0564045  0.0187673 ]] - model q_values
[[0.75599885 1.0564045  0.0187673 ]] - step_model q_values
[[0.75599885 1.0564045  0.0187673 ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  46.57789

num_timesteps:  1258
[[0.6864047  0.98514587 0.06375551]] - model q_values
[[0.6864047  0.98514587 0.06375551]] - step_model q_values
[[0.6864047  0.98514587 0.06375551]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  46.57789

num_timesteps:  1259
[[0.8582467  1.2360657  0.10581976]] - model q_values
[[0.8582467  1.2360657  0.10581976]] - step_model q_values
[[0.8582467  1.2360657  0.10581976]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  46.57789

num_timesteps:  1260
[[0.6327653 1.0283927 0.2675203]] - model q_values
[[0.6327653 1.0283927 0.2675203]] - step_model q_values
[[0.6327653 1.0283927 0.2675203]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  46.57789

num_timesteps:  1261
[[0.6084381  0.7956544  0.06718335]] - model q_values
[[0.6084381  0.7956544  0.06718335]] - step_model q_values
[[0.6084381  0.7956544  0.06718335]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  46.726486

num_timesteps:  1262
[[0.548961   0.70224494 0.11674288]] - model q_values
[[0.548961   0.70224494 0.11674288]] - step_model q_values
[[0.548961   0.70224494 0.11674288]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  46.726486

num_timesteps:  1263
[[0.72563964 0.97080743 0.16765583]] - model q_values
[[0.72563964 0.97080743 0.16765583]] - step_model q_values
[[0.72563964 0.97080743 0.16765583]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  46.726486

num_timesteps:  1264
[[0.50251466 0.785619   0.3370976 ]] - model q_values
[[0.50251466 0.785619   0.3370976 ]] - step_model q_values
[[0.50251466 0.785619   0.3370976 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  46.726486

num_timesteps:  1265
[[0.46646088 0.5555442  0.14356127]] - model q_values
[[0.46646088 0.5555442  0.14356127]] - step_model q_values
[[0.46646088 0.5555442  0.14356127]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  46.863216

num_timesteps:  1266
[[0.40126356 0.46146253 0.23783942]] - model q_values
[[0.40126356 0.46146253 0.23783942]] - step_model q_values
[[0.40126356 0.46146253 0.23783942]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  46.894356

num_timesteps:  1267
[[0.5808429  0.7477028  0.30022287]] - model q_values
[[0.5808429  0.7477028  0.30022287]] - step_model q_values
[[0.5808429  0.7477028  0.30022287]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  46.894356

num_timesteps:  1268
[[0.3684163 0.5882471 0.449815 ]] - model q_values
[[0.3684163 0.5882471 0.449815 ]] - step_model q_values
[[0.3684163 0.5882471 0.449815 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  46.95493

num_timesteps:  1269
[[0.332047   0.37314498 0.22463271]] - model q_values
[[0.332047   0.37314498 0.22463271]] - step_model q_values
[[0.332047   0.37314498 0.22463271]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  46.982193

num_timesteps:  1270
[[0.27547553 0.29183194 0.32809716]] - model q_values
[[0.27547553 0.29183194 0.32809716]] - step_model q_values
[[0.27547553 0.29183194 0.32809716]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.008026

num_timesteps:  1271
[[0.26819235 0.3175265  0.27412245]] - model q_values
[[0.26819235 0.3175265  0.27412245]] - step_model q_values
[[0.26819235 0.3175265  0.27412245]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.043133

num_timesteps:  1272
[[0.1986314  0.25147587 0.4781154 ]] - model q_values
[[0.1986314  0.25147587 0.4781154 ]] - step_model q_values
[[0.1986314  0.25147587 0.4781154 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.043133

num_timesteps:  1273
[[0.18973961 0.30870903 0.4891059 ]] - model q_values
[[0.18973961 0.30870903 0.4891059 ]] - step_model q_values
[[0.18973961 0.30870903 0.4891059 ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.043133

num_timesteps:  1274
[[0.1644972  0.49377143 0.86414194]] - model q_values
[[0.1644972  0.49377143 0.86414194]] - step_model q_values
[[0.1644972  0.49377143 0.86414194]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.164787

num_timesteps:  1275
[[0.29647937 0.6195709  0.9489368 ]] - model q_values
[[0.29647937 0.6195709  0.9489368 ]] - step_model q_values
[[0.29647937 0.6195709  0.9489368 ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.204838

num_timesteps:  1276
[[0.03428316 0.31083405 1.134775  ]] - model q_values
[[0.03428316 0.31083405 1.134775  ]] - step_model q_values
[[0.03428316 0.31083405 1.134775  ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.204838

num_timesteps:  1277
[[0.02456921 0.40321988 1.274408  ]] - model q_values
[[0.02456921 0.40321988 1.274408  ]] - step_model q_values
[[0.02456921 0.40321988 1.274408  ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.204838

num_timesteps:  1278
[[-0.00479472  0.59044266  1.7545085 ]] - model q_values
[[-0.00479472  0.59044266  1.7545085 ]] - step_model q_values
[[-0.00479472  0.59044266  1.7545085 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.204838

num_timesteps:  1279
[[0.11378419 0.7311766  1.9748292 ]] - model q_values
[[0.11378419 0.7311766  1.9748292 ]] - step_model q_values
[[0.11378419 0.7311766  1.9748292 ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.40531

num_timesteps:  1280
[[-0.15466046  0.4599949   2.2779007 ]] - model q_values
[[-0.15466046  0.4599949   2.2779007 ]] - step_model q_values
[[-0.15466046  0.4599949   2.2779007 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.40531

num_timesteps:  1281
[[-0.15592277  0.56506324  2.4866102 ]] - model q_values
[[-0.15592277  0.56506324  2.4866102 ]] - step_model q_values
[[-0.15592277  0.56506324  2.4866102 ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.518303

num_timesteps:  1282
[[-0.2246213  0.7037093  2.9556909]] - model q_values
[[-0.2246213  0.7037093  2.9556909]] - step_model q_values
[[-0.2246213  0.7037093  2.9556909]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.518303

num_timesteps:  1283
[[-0.13182175  0.82856965  3.2033195 ]] - model q_values
[[-0.13182175  0.82856965  3.2033195 ]] - step_model q_values
[[-0.13182175  0.82856965  3.2033195 ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.518303

num_timesteps:  1284
[[-0.37510204  0.6155233   3.5297003 ]] - model q_values
[[-0.37510204  0.6155233   3.5297003 ]] - step_model q_values
[[-0.37510204  0.6155233   3.5297003 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.518303

num_timesteps:  1285
[[-0.35313582  0.749371    3.716939  ]] - model q_values
[[-0.35313582  0.749371    3.716939  ]] - step_model q_values
[[-0.35313582  0.749371    3.716939  ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.518303

num_timesteps:  1286
[[-0.46186686  0.804673    4.1013055 ]] - model q_values
[[-0.46186686  0.804673    4.1013055 ]] - step_model q_values
[[-0.46186686  0.804673    4.1013055 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.518303

num_timesteps:  1287
[[-0.35715687  0.9431753   4.353574  ]] - model q_values
[[-0.35715687  0.9431753   4.353574  ]] - step_model q_values
[[-0.35715687  0.9431753   4.353574  ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.518303

num_timesteps:  1288
[[-0.5877451   0.78581643  4.5770264 ]] - model q_values
[[-0.5877451   0.78581643  4.5770264 ]] - step_model q_values
[[-0.5877451   0.78581643  4.5770264 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.518303

num_timesteps:  1289
[[-0.5482856   0.93246424  4.6705337 ]] - model q_values
[[-0.5482856   0.93246424  4.6705337 ]] - step_model q_values
[[-0.5482856   0.93246424  4.6705337 ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1290
[[-0.602996   0.9687932  4.8400435]] - model q_values
[[-0.602996   0.9687932  4.8400435]] - step_model q_values
[[-0.602996   0.9687932  4.8400435]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1291
[[-0.43667233  1.1233397   4.896701  ]] - model q_values
[[-0.43667233  1.1233397   4.896701  ]] - step_model q_values
[[-0.43667233  1.1233397   4.896701  ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1292
[[-0.6085019  0.9892976  4.867543 ]] - model q_values
[[-0.6085019  0.9892976  4.867543 ]] - step_model q_values
[[-0.6085019  0.9892976  4.867543 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1293
[[-0.50920236  1.1288362   4.762952  ]] - model q_values
[[-0.50920236  1.1288362   4.762952  ]] - step_model q_values
[[-0.50920236  1.1288362   4.762952  ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1294
[[-0.5159917  1.1691949  4.740342 ]] - model q_values
[[-0.5159917  1.1691949  4.740342 ]] - step_model q_values
[[-0.5159917  1.1691949  4.740342 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1295
[[-0.32633567  1.3363509   4.631448  ]] - model q_values
[[-0.32633567  1.3363509   4.631448  ]] - step_model q_values
[[-0.32633567  1.3363509   4.631448  ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1296
[[-0.47514188  1.2139788   4.432503  ]] - model q_values
[[-0.47514188  1.2139788   4.432503  ]] - step_model q_values
[[-0.47514188  1.2139788   4.432503  ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1297
[[-0.35240757  1.3299733   4.246369  ]] - model q_values
[[-0.35240757  1.3299733   4.246369  ]] - step_model q_values
[[-0.35240757  1.3299733   4.246369  ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1298
[[-0.34896255  1.3936951   4.194426  ]] - model q_values
[[-0.34896255  1.3936951   4.194426  ]] - step_model q_values
[[-0.34896255  1.3936951   4.194426  ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1299
[[-0.15874851  1.5492315   3.9883447 ]] - model q_values
[[-0.15874851  1.5492315   3.9883447 ]] - step_model q_values
[[-0.15874851  1.5492315   3.9883447 ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1300
[[-0.28558922  1.4398468   3.7582135 ]] - model q_values
[[-0.28558922  1.4398468   3.7582135 ]] - step_model q_values
[[-0.28558922  1.4398468   3.7582135 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1301
[[-0.15708506  1.5203984   3.6295028 ]] - model q_values
[[-0.15708506  1.5203984   3.6295028 ]] - step_model q_values
[[-0.15708506  1.5203984   3.6295028 ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1302
[[-0.17289495  1.5937786   3.6530771 ]] - model q_values
[[-0.17289495  1.5937786   3.6530771 ]] - step_model q_values
[[-0.17289495  1.5937786   3.6530771 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1303
[[3.0528307e-03 1.7592360e+00 3.4866388e+00]] - model q_values
[[3.0528307e-03 1.7592360e+00 3.4866388e+00]] - step_model q_values
[[3.0528307e-03 1.7592360e+00 3.4866388e+00]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1304
[[-0.137604   1.6554563  3.3437595]] - model q_values
[[-0.137604   1.6554563  3.3437595]] - step_model q_values
[[-0.137604   1.6554563  3.3437595]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1305
[[-0.02884638  1.7124305   3.3500876 ]] - model q_values
[[-0.02884638  1.7124305   3.3500876 ]] - step_model q_values
[[-0.02884638  1.7124305   3.3500876 ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1306
[[-0.08023834  1.7753484   3.4972863 ]] - model q_values
[[-0.08023834  1.7753484   3.4972863 ]] - step_model q_values
[[-0.08023834  1.7753484   3.4972863 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1307
[[0.0808928 1.9592178 3.3819518]] - model q_values
[[0.0808928 1.9592178 3.3819518]] - step_model q_values
[[0.0808928 1.9592178 3.3819518]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1308
[[-0.07484579  1.8529744   3.3068316 ]] - model q_values
[[-0.07484579  1.8529744   3.3068316 ]] - step_model q_values
[[-0.07484579  1.8529744   3.3068316 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1309
[[0.01344573 1.8943305  3.4484797 ]] - model q_values
[[0.01344573 1.8943305  3.4484797 ]] - step_model q_values
[[0.01344573 1.8943305  3.4484797 ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1310
[[-0.05400348  1.9449265   3.6795447 ]] - model q_values
[[-0.05400348  1.9449265   3.6795447 ]] - step_model q_values
[[-0.05400348  1.9449265   3.6795447 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1311
[[0.09245062 2.1515343  3.609777  ]] - model q_values
[[0.09245062 2.1515343  3.609777  ]] - step_model q_values
[[0.09245062 2.1515343  3.609777  ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1312
[[-0.07386374  2.0400195   3.572007  ]] - model q_values
[[-0.07386374  2.0400195   3.572007  ]] - step_model q_values
[[-0.07386374  2.0400195   3.572007  ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1313
[[-0.00435674  2.0863407   3.7784824 ]] - model q_values
[[-0.00435674  2.0863407   3.7784824 ]] - step_model q_values
[[-0.00435674  2.0863407   3.7784824 ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1314
[[-0.06977248  2.1326642   4.025015  ]] - model q_values
[[-0.06977248  2.1326642   4.025015  ]] - step_model q_values
[[-0.06977248  2.1326642   4.025015  ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1315
[[0.07274365 2.350344   3.9484556 ]] - model q_values
[[0.07274365 2.350344   3.9484556 ]] - step_model q_values
[[0.07274365 2.350344   3.9484556 ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1316
[[-0.09756064  2.2359414   3.884411  ]] - model q_values
[[-0.09756064  2.2359414   3.884411  ]] - step_model q_values
[[-0.09756064  2.2359414   3.884411  ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1317
[[-0.03846669  2.273035    4.088535  ]] - model q_values
[[-0.03846669  2.273035    4.088535  ]] - step_model q_values
[[-0.03846669  2.273035    4.088535  ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1318
[[-0.09567833  2.3118672   4.286099  ]] - model q_values
[[-0.09567833  2.3118672   4.286099  ]] - step_model q_values
[[-0.09567833  2.3118672   4.286099  ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1319
[[0.07103395 2.5492432  4.132037  ]] - model q_values
[[0.07103395 2.5492432  4.132037  ]] - step_model q_values
[[0.07103395 2.5492432  4.132037  ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1320
[[-0.09259415  2.4378057   4.0023713 ]] - model q_values
[[-0.09259415  2.4378057   4.0023713 ]] - step_model q_values
[[-0.09259415  2.4378057   4.0023713 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1321
[[-0.02683496  2.459217    4.16176   ]] - model q_values
[[-0.02683496  2.459217    4.16176   ]] - step_model q_values
[[-0.02683496  2.459217    4.16176   ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1322
[[-0.07529068  2.4913514   4.2983828 ]] - model q_values
[[-0.07529068  2.4913514   4.2983828 ]] - step_model q_values
[[-0.07529068  2.4913514   4.2983828 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1323
[[0.1034987 2.7363462 4.09468  ]] - model q_values
[[0.1034987 2.7363462 4.09468  ]] - step_model q_values
[[0.1034987 2.7363462 4.09468  ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1324
[[-0.055655   2.627464   3.9077492]] - model q_values
[[-0.055655   2.627464   3.9077492]] - step_model q_values
[[-0.055655   2.627464   3.9077492]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1325
[[0.01196933 2.6328182  4.072732  ]] - model q_values
[[0.01196933 2.6328182  4.072732  ]] - step_model q_values
[[0.01196933 2.6328182  4.072732  ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1326
[[-0.03230882  2.722786    3.8403432 ]] - model q_values
[[-0.03230882  2.722786    3.8403432 ]] - step_model q_values
[[-0.03230882  2.722786    3.8403432 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1327
[[0.03841901 2.7171133  3.9993477 ]] - model q_values
[[0.03841901 2.7171133  3.9993477 ]] - step_model q_values
[[0.03841901 2.7171133  3.9993477 ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1328
[[-0.006037   2.7462134  4.1255617]] - model q_values
[[-0.006037   2.7462134  4.1255617]] - step_model q_values
[[-0.006037   2.7462134  4.1255617]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1329
[[0.17736292 3.0002608  3.9110231 ]] - model q_values
[[0.17736292 3.0002608  3.9110231 ]] - step_model q_values
[[0.17736292 3.0002608  3.9110231 ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1330
[[0.02719092 2.89697    3.6728055 ]] - model q_values
[[0.02719092 2.89697    3.6728055 ]] - step_model q_values
[[0.02719092 2.89697    3.6728055 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1331
[[0.09608054 2.8748455  3.869313  ]] - model q_values
[[0.09608054 2.8748455  3.869313  ]] - step_model q_values
[[0.09608054 2.8748455  3.869313  ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1332
[[0.05880189 2.9017777  3.963726  ]] - model q_values
[[0.05880189 2.9017777  3.963726  ]] - step_model q_values
[[0.05880189 2.9017777  3.963726  ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1333
[[0.24856615 3.1649756  3.695661  ]] - model q_values
[[0.24856615 3.1649756  3.695661  ]] - step_model q_values
[[0.24856615 3.1649756  3.695661  ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1334
[[0.11076093 3.0794382  3.3941011 ]] - model q_values
[[0.11076093 3.0794382  3.3941011 ]] - step_model q_values
[[0.11076093 3.0794382  3.3941011 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1335
[[0.1839261 3.0372195 3.5620236]] - model q_values
[[0.1839261 3.0372195 3.5620236]] - step_model q_values
[[0.1839261 3.0372195 3.5620236]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1336
[[0.14754224 3.0541754  3.667943  ]] - model q_values
[[0.14754224 3.0541754  3.667943  ]] - step_model q_values
[[0.14754224 3.0541754  3.667943  ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1337
[[0.3371234 3.318543  3.382308 ]] - model q_values
[[0.3371234 3.318543  3.382308 ]] - step_model q_values
[[0.3371234 3.318543  3.382308 ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1338
[[0.20421994 3.2407703  3.0407944 ]] - model q_values
[[0.20421994 3.2407703  3.0407944 ]] - step_model q_values
[[0.20421994 3.2407703  3.0407944 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1339
[[0.38208902 3.3920789  3.199747  ]] - model q_values
[[0.38208902 3.3920789  3.199747  ]] - step_model q_values
[[0.38208902 3.3920789  3.199747  ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1340
[[0.23889613 3.1904943  3.315547  ]] - model q_values
[[0.23889613 3.1904943  3.315547  ]] - step_model q_values
[[0.23889613 3.1904943  3.315547  ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1341
[[0.43194222 3.4440863  2.9952388 ]] - model q_values
[[0.43194222 3.4440863  2.9952388 ]] - step_model q_values
[[0.43194222 3.4440863  2.9952388 ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1342
[[0.28766096 3.2323823  3.1384335 ]] - model q_values
[[0.28766096 3.2323823  3.1384335 ]] - step_model q_values
[[0.28766096 3.2323823  3.1384335 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1343
[[0.36990905 3.2694414  2.867032  ]] - model q_values
[[0.36990905 3.2694414  2.867032  ]] - step_model q_values
[[0.36990905 3.2694414  2.867032  ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1344
[[0.36720884 3.3942895  2.4068322 ]] - model q_values
[[0.36720884 3.3942895  2.4068322 ]] - step_model q_values
[[0.36720884 3.3942895  2.4068322 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1345
[[0.5423131 3.5005312 2.5539637]] - model q_values
[[0.5423131 3.5005312 2.5539637]] - step_model q_values
[[0.5423131 3.5005312 2.5539637]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1346
[[0.43711317 3.4046607  2.100365  ]] - model q_values
[[0.43711317 3.4046607  2.100365  ]] - step_model q_values
[[0.43711317 3.4046607  2.100365  ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1347
[[0.6122457 3.498919  2.2008293]] - model q_values
[[0.6122457 3.498919  2.2008293]] - step_model q_values
[[0.6122457 3.498919  2.2008293]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1348
[[0.48247743 3.2619934  2.2464685 ]] - model q_values
[[0.48247743 3.2619934  2.2464685 ]] - step_model q_values
[[0.48247743 3.2619934  2.2464685 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1349
[[0.59161437 3.253583   1.8089945 ]] - model q_values
[[0.59161437 3.253583   1.8089945 ]] - step_model q_values
[[0.59161437 3.253583   1.8089945 ]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1350
[[0.60566294 3.3822355  1.1494389 ]] - model q_values
[[0.60566294 3.3822355  1.1494389 ]] - step_model q_values
[[0.60566294 3.3822355  1.1494389 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1351
[[0.77621293 3.4548244  1.2137113 ]] - model q_values
[[0.77621293 3.4548244  1.2137113 ]] - step_model q_values
[[0.77621293 3.4548244  1.2137113 ]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1352
[[0.64920807 3.2110682  1.2045883 ]] - model q_values
[[0.64920807 3.2110682  1.2045883 ]] - step_model q_values
[[0.64920807 3.2110682  1.2045883 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1353
[[0.7685384  3.1843224  0.67870617]] - model q_values
[[0.7685384  3.1843224  0.67870617]] - step_model q_values
[[0.7685384  3.1843224  0.67870617]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1354
[[ 0.7775867   3.3111386  -0.01703322]] - model q_values
[[ 0.7775867   3.3111386  -0.01703322]] - step_model q_values
[[ 0.7775867   3.3111386  -0.01703322]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1355
[[0.9430416  3.3844676  0.03331828]] - model q_values
[[0.9430416  3.3844676  0.03331828]] - step_model q_values
[[0.9430416  3.3844676  0.03331828]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1356
[[0.799572   3.131242   0.07150531]] - model q_values
[[0.799572   3.131242   0.07150531]] - step_model q_values
[[0.799572   3.131242   0.07150531]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1357
[[ 0.9129729   3.0946174  -0.42410946]] - model q_values
[[ 0.9129729   3.0946174  -0.42410946]] - step_model q_values
[[ 0.9129729   3.0946174  -0.42410946]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1358
[[ 0.9134444  3.211224  -0.9981617]] - model q_values
[[ 0.9134444  3.211224  -0.9981617]] - step_model q_values
[[ 0.9134444  3.211224  -0.9981617]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1359
[[ 1.0652602   3.28159    -0.81540954]] - model q_values
[[ 1.0652602   3.28159    -0.81540954]] - step_model q_values
[[ 1.0652602   3.28159    -0.81540954]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1360
[[ 0.900985    3.0082636  -0.60430765]] - model q_values
[[ 0.900985    3.0082636  -0.60430765]] - step_model q_values
[[ 0.900985    3.0082636  -0.60430765]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1361
[[ 1.0009162   2.9492037  -0.94702053]] - model q_values
[[ 1.0009162   2.9492037  -0.94702053]] - step_model q_values
[[ 1.0009162   2.9492037  -0.94702053]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1362
[[ 0.9801835  3.0346677 -1.3089643]] - model q_values
[[ 0.9801835  3.0346677 -1.3089643]] - step_model q_values
[[ 0.9801835  3.0346677 -1.3089643]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1363
[[ 1.1096295   3.1094623  -0.96430254]] - model q_values
[[ 1.1096295   3.1094623  -0.96430254]] - step_model q_values
[[ 1.1096295   3.1094623  -0.96430254]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1364
[[ 0.92477846  2.8327866  -0.59283435]] - model q_values
[[ 0.92477846  2.8327866  -0.59283435]] - step_model q_values
[[ 0.92477846  2.8327866  -0.59283435]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1365
[[ 1.0036219  2.7589765 -0.7711786]] - model q_values
[[ 1.0036219  2.7589765 -0.7711786]] - step_model q_values
[[ 1.0036219  2.7589765 -0.7711786]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1366
[[ 0.96628815  2.8248017  -0.9980653 ]] - model q_values
[[ 0.96628815  2.8248017  -0.9980653 ]] - step_model q_values
[[ 0.96628815  2.8248017  -0.9980653 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1367
[[ 1.0914264  2.8896341 -0.5496185]] - model q_values
[[ 1.0914264  2.8896341 -0.5496185]] - step_model q_values
[[ 1.0914264  2.8896341 -0.5496185]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1368
[[ 0.9023249   2.6115835  -0.12357795]] - model q_values
[[ 0.9023249   2.6115835  -0.12357795]] - step_model q_values
[[ 0.9023249   2.6115835  -0.12357795]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1369
[[ 0.97549963  2.5212486  -0.23410547]] - model q_values
[[ 0.97549963  2.5212486  -0.23410547]] - step_model q_values
[[ 0.97549963  2.5212486  -0.23410547]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1370
[[ 0.9343066   2.5690885  -0.45901048]] - model q_values
[[ 0.9343066   2.5690885  -0.45901048]] - step_model q_values
[[ 0.9343066   2.5690885  -0.45901048]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1371
[[ 1.053963    2.642147   -0.04395843]] - model q_values
[[ 1.053963    2.642147   -0.04395843]] - step_model q_values
[[ 1.053963    2.642147   -0.04395843]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1372
[[0.85585463 2.3714445  0.33409595]] - model q_values
[[0.85585463 2.3714445  0.33409595]] - step_model q_values
[[0.85585463 2.3714445  0.33409595]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1373
[[0.9205688  2.274497   0.21696109]] - model q_values
[[0.9205688  2.274497   0.21696109]] - step_model q_values
[[0.9205688  2.274497   0.21696109]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1374
[[ 0.8795523   2.296187   -0.02188754]] - model q_values
[[ 0.8795523   2.296187   -0.02188754]] - step_model q_values
[[ 0.8795523   2.296187   -0.02188754]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1375
[[1.0047407  2.3960526  0.32207173]] - model q_values
[[1.0047407  2.3960526  0.32207173]] - step_model q_values
[[1.0047407  2.3960526  0.32207173]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1376
[[0.81457436 2.141036   0.6321894 ]] - model q_values
[[0.81457436 2.141036   0.6321894 ]] - step_model q_values
[[0.81457436 2.141036   0.6321894 ]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1377
[[0.88154304 2.0449493  0.47880483]] - model q_values
[[0.88154304 2.0449493  0.47880483]] - step_model q_values
[[0.88154304 2.0449493  0.47880483]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1378
[[0.84751064 2.0441623  0.21320611]] - model q_values
[[0.84751064 2.0441623  0.21320611]] - step_model q_values
[[0.84751064 2.0441623  0.21320611]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1379
[[0.9765909  2.1698277  0.48025423]] - model q_values
[[0.9765909  2.1698277  0.48025423]] - step_model q_values
[[0.9765909  2.1698277  0.48025423]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1380
[[0.7940476 1.9180381 0.7248794]] - model q_values
[[0.7940476 1.9180381 0.7248794]] - step_model q_values
[[0.7940476 1.9180381 0.7248794]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1381
[[0.86098856 1.8208423  0.51692086]] - model q_values
[[0.86098856 1.8208423  0.51692086]] - step_model q_values
[[0.86098856 1.8208423  0.51692086]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1382
[[0.83496726 1.7978611  0.2376501 ]] - model q_values
[[0.83496726 1.7978611  0.2376501 ]] - step_model q_values
[[0.83496726 1.7978611  0.2376501 ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1383
[[0.9671566  1.9392114  0.43250376]] - model q_values
[[0.9671566  1.9392114  0.43250376]] - step_model q_values
[[0.9671566  1.9392114  0.43250376]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1384
[[0.78979903 1.6924423  0.60652834]] - model q_values
[[0.78979903 1.6924423  0.60652834]] - step_model q_values
[[0.78979903 1.6924423  0.60652834]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1385
[[0.8605922 1.5899029 0.3431279]] - model q_values
[[0.8605922 1.5899029 0.3431279]] - step_model q_values
[[0.8605922 1.5899029 0.3431279]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1386
[[0.84430623 1.5507165  0.06451768]] - model q_values
[[0.84430623 1.5507165  0.06451768]] - step_model q_values
[[0.84430623 1.5507165  0.06451768]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1387
[[0.97657824 1.7183223  0.19857508]] - model q_values
[[0.97657824 1.7183223  0.19857508]] - step_model q_values
[[0.97657824 1.7183223  0.19857508]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1388
[[0.79753804 1.4760714  0.34830457]] - model q_values
[[0.79753804 1.4760714  0.34830457]] - step_model q_values
[[0.79753804 1.4760714  0.34830457]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1389
[[0.86991507 1.3704176  0.06176817]] - model q_values
[[0.86991507 1.3704176  0.06176817]] - step_model q_values
[[0.86991507 1.3704176  0.06176817]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1390
[[ 0.8594731  1.3079855 -0.1649943]] - model q_values
[[ 0.8594731  1.3079855 -0.1649943]] - step_model q_values
[[ 0.8594731  1.3079855 -0.1649943]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1391
[[ 0.9898279   1.4951329  -0.03997922]] - model q_values
[[ 0.9898279   1.4951329  -0.03997922]] - step_model q_values
[[ 0.9898279   1.4951329  -0.03997922]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1392
[[0.80781466 1.2500713  0.13236558]] - model q_values
[[0.80781466 1.2500713  0.13236558]] - step_model q_values
[[0.80781466 1.2500713  0.13236558]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1393
[[ 0.88248646  1.140116   -0.14377654]] - model q_values
[[ 0.88248646  1.140116   -0.14377654]] - step_model q_values
[[ 0.88248646  1.140116   -0.14377654]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1394
[[ 0.87296957  1.0536829  -0.29792148]] - model q_values
[[ 0.87296957  1.0536829  -0.29792148]] - step_model q_values
[[ 0.87296957  1.0536829  -0.29792148]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1395
[[ 1.0048909  1.2612348 -0.1579895]] - model q_values
[[ 1.0048909  1.2612348 -0.1579895]] - step_model q_values
[[ 1.0048909  1.2612348 -0.1579895]] - double_policy q_values
[[0.91074204 1.1833732  5.312855  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1396
[[0.8183482  1.018147   0.04030752]] - model q_values
[[0.8183482  1.018147   0.04030752]] - step_model q_values
[[0.8183482  1.018147   0.04030752]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1397
[[ 0.8910966   0.89985156 -0.21011466]] - model q_values
[[ 0.8910966   0.89985156 -0.21011466]] - step_model q_values
[[ 0.8910966   0.89985156 -0.21011466]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1398
[[ 0.87656134  0.7887124  -0.303849  ]] - model q_values
[[ 0.87656134  0.7887124  -0.303849  ]] - step_model q_values
[[ 0.87656134  0.7887124  -0.303849  ]] - double_policy q_values
[[0.987267  1.0128604 5.4306264]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1399
[[ 0.34948704  1.4395127  -0.01206225]] - model q_values
[[ 0.34948704  1.4395127  -0.01206225]] - step_model q_values
[[ 0.34948704  1.4395127  -0.01206225]] - double_policy q_values
[[0.04857659 1.7575951  3.8568597 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1400
[[ 3.8790717  2.767446  -1.880554 ]] - model q_values
[[ 3.8790717  2.767446  -1.880554 ]] - step_model q_values
[[ 3.8790717  2.767446  -1.880554 ]] - double_policy q_values
[[3.5860157 3.6066353 2.8221166]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1401
[[ 3.6873822  2.8924785 -2.2020106]] - model q_values
[[ 3.6873822  2.8924785 -2.2020106]] - step_model q_values
[[ 3.6873822  2.8924785 -2.2020106]] - double_policy q_values
[[2.7708485 3.4598932 2.008137 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1402
[[0.48069894 0.7455443  0.41215336]] - model q_values
[[0.48069894 0.7455443  0.41215336]] - step_model q_values
[[0.48069894 0.7455443  0.41215336]] - double_policy q_values
[[-0.29712677  0.8986474   3.997241  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1403
[[ 2.1259665  -0.08876961 -0.309505  ]] - model q_values
[[ 2.1259665  -0.08876961 -0.309505  ]] - step_model q_values
[[ 2.1259665  -0.08876961 -0.309505  ]] - double_policy q_values
[[ 0.6529273 -0.1978811  2.300149 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1404
[[ 1.0397635   0.60097164 -0.17251387]] - model q_values
[[ 1.0397635   0.60097164 -0.17251387]] - step_model q_values
[[ 1.0397635   0.60097164 -0.17251387]] - double_policy q_values
[[1.1123072 1.1941737 5.3480797]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1405
[[0.4557012  1.1912417  0.17586488]] - model q_values
[[0.4557012  1.1912417  0.17586488]] - step_model q_values
[[0.4557012  1.1912417  0.17586488]] - double_policy q_values
[[0.25199306 1.7207047  4.167053  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1406
[[0.8742005  0.38257584 0.02653363]] - model q_values
[[0.8742005  0.38257584 0.02653363]] - step_model q_values
[[0.8742005  0.38257584 0.02653363]] - double_policy q_values
[[0.4469334  0.99953413 4.706278  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1407
[[0.79650545 0.41922456 0.25938553]] - model q_values
[[0.79650545 0.41922456 0.25938553]] - step_model q_values
[[0.79650545 0.41922456 0.25938553]] - double_policy q_values
[[0.595953  1.0350266 5.2186756]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1408
[[0.78642964 0.5402414  0.46664143]] - model q_values
[[0.78642964 0.5402414  0.46664143]] - step_model q_values
[[0.78642964 0.5402414  0.46664143]] - double_policy q_values
[[0.5774921 1.1709594 5.316329 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1409
[[0.7378181 0.6335297 0.6648474]] - model q_values
[[0.7378181 0.6335297 0.6648474]] - step_model q_values
[[0.7378181 0.6335297 0.6648474]] - double_policy q_values
[[0.48293817 1.2397107  5.3261085 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1410
[[0.8394889 1.0428903 0.9989635]] - model q_values
[[0.8394889 1.0428903 0.9989635]] - step_model q_values
[[0.8394889 1.0428903 0.9989635]] - double_policy q_values
[[0.4724431 1.5731843 5.5356407]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1411
[[0.2760441  0.60456085 0.30121535]] - model q_values
[[0.2760441  0.60456085 0.30121535]] - step_model q_values
[[0.2760441  0.60456085 0.30121535]] - double_policy q_values
[[-0.87388146  0.9768264   2.6303802 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1412
[[ 2.7957654  1.1943858 -1.536746 ]] - model q_values
[[ 2.7957654  1.1943858 -1.536746 ]] - step_model q_values
[[ 2.7957654  1.1943858 -1.536746 ]] - double_policy q_values
[[2.883488  2.7910142 4.1486506]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1413
[[ 3.0203109  1.2828096 -1.6188835]] - model q_values
[[ 3.0203109  1.2828096 -1.6188835]] - step_model q_values
[[ 3.0203109  1.2828096 -1.6188835]] - double_policy q_values
[[3.144597  2.9546103 3.9618847]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1414
[[ 3.2723527  1.3528004 -1.6925044]] - model q_values
[[ 3.2723527  1.3528004 -1.6925044]] - step_model q_values
[[ 3.2723527  1.3528004 -1.6925044]] - double_policy q_values
[[3.3748322 3.139287  3.7583022]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1415
[[ 3.545806   1.4586471 -1.7407142]] - model q_values
[[ 3.545806   1.4586471 -1.7407142]] - step_model q_values
[[ 3.545806   1.4586471 -1.7407142]] - double_policy q_values
[[3.603202  3.3265038 3.5540457]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1416
[[ 4.1997643  2.0501742 -1.7302195]] - model q_values
[[ 4.1997643  2.0501742 -1.7302195]] - step_model q_values
[[ 4.1997643  2.0501742 -1.7302195]] - double_policy q_values
[[3.8528905 3.8543394 3.0124688]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1417
[[1.4865341 1.823585  1.4004395]] - model q_values
[[1.4865341 1.823585  1.4004395]] - step_model q_values
[[1.4865341 1.823585  1.4004395]] - double_policy q_values
[[0.6595924 2.6243587 4.916577 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1418
[[ 1.2217274   0.01036838 -0.24977279]] - model q_values
[[ 1.2217274   0.01036838 -0.24977279]] - step_model q_values
[[ 1.2217274   0.01036838 -0.24977279]] - double_policy q_values
[[2.0590744 1.4259531 6.250065 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1419
[[ 1.2568787   0.10176465 -0.18856755]] - model q_values
[[ 1.2568787   0.10176465 -0.18856755]] - step_model q_values
[[ 1.2568787   0.10176465 -0.18856755]] - double_policy q_values
[[1.9596337 1.3982874 6.137355 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1420
[[ 1.4879543   0.5093955  -0.10324419]] - model q_values
[[ 1.4879543   0.5093955  -0.10324419]] - step_model q_values
[[ 1.4879543   0.5093955  -0.10324419]] - double_policy q_values
[[2.012568  1.6576153 5.900246 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1421
[[ 1.5113685e+00  6.6812038e-01 -1.0686517e-03]] - model q_values
[[ 1.5113685e+00  6.6812038e-01 -1.0686517e-03]] - step_model q_values
[[ 1.5113685e+00  6.6812038e-01 -1.0686517e-03]] - double_policy q_values
[[1.9354621 1.6924827 5.7600517]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1422
[[ 1.48645     0.82299626 -0.00633073]] - model q_values
[[ 1.48645     0.82299626 -0.00633073]] - step_model q_values
[[ 1.48645     0.82299626 -0.00633073]] - double_policy q_values
[[1.7847227 1.656781  5.580959 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1423
[[1.6378293  1.3197142  0.24617457]] - model q_values
[[1.6378293  1.3197142  0.24617457]] - step_model q_values
[[1.6378293  1.3197142  0.24617457]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1424
[[1.6310992 1.2987475 0.2716086]] - model q_values
[[1.6310992 1.2987475 0.2716086]] - step_model q_values
[[1.6310992 1.2987475 0.2716086]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1425
[[1.6223166 1.2783694 0.3011849]] - model q_values
[[1.6223166 1.2783694 0.3011849]] - step_model q_values
[[1.6223166 1.2783694 0.3011849]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1426
[[1.6138027 1.2606348 0.3313381]] - model q_values
[[1.6138027 1.2606348 0.3313381]] - step_model q_values
[[1.6138027 1.2606348 0.3313381]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1427
[[1.6064811 1.2453611 0.3685485]] - model q_values
[[1.6064811 1.2453611 0.3685485]] - step_model q_values
[[1.6064811 1.2453611 0.3685485]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1428
[[1.599831  1.2361623 0.4020989]] - model q_values
[[1.599831  1.2361623 0.4020989]] - step_model q_values
[[1.599831  1.2361623 0.4020989]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1429
[[1.5931708  1.2287238  0.43668443]] - model q_values
[[1.5931708  1.2287238  0.43668443]] - step_model q_values
[[1.5931708  1.2287238  0.43668443]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1430
[[1.5856652  1.2208194  0.47757238]] - model q_values
[[1.5856652  1.2208194  0.47757238]] - step_model q_values
[[1.5856652  1.2208194  0.47757238]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1431
[[1.5773034 1.2155306 0.5184613]] - model q_values
[[1.5773034 1.2155306 0.5184613]] - step_model q_values
[[1.5773034 1.2155306 0.5184613]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1432
[[1.5687134  1.2136643  0.56002355]] - model q_values
[[1.5687134  1.2136643  0.56002355]] - step_model q_values
[[1.5687134  1.2136643  0.56002355]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1433
[[1.5579944 1.21233   0.5990423]] - model q_values
[[1.5579944 1.21233   0.5990423]] - step_model q_values
[[1.5579944 1.21233   0.5990423]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1434
[[1.5488164 1.2141287 0.6302953]] - model q_values
[[1.5488164 1.2141287 0.6302953]] - step_model q_values
[[1.5488164 1.2141287 0.6302953]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1435
[[1.5408055  1.2161024  0.67043465]] - model q_values
[[1.5408055  1.2161024  0.67043465]] - step_model q_values
[[1.5408055  1.2161024  0.67043465]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1436
[[1.5331792 1.2196368 0.708583 ]] - model q_values
[[1.5331792 1.2196368 0.708583 ]] - step_model q_values
[[1.5331792 1.2196368 0.708583 ]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1437
[[1.5257745 1.2244546 0.7470634]] - model q_values
[[1.5257745 1.2244546 0.7470634]] - step_model q_values
[[1.5257745 1.2244546 0.7470634]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1438
[[1.5193716  1.2318424  0.77697444]] - model q_values
[[1.5193716  1.2318424  0.77697444]] - step_model q_values
[[1.5193716  1.2318424  0.77697444]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1439
[[1.5159634 1.2386811 0.7922025]] - model q_values
[[1.5159634 1.2386811 0.7922025]] - step_model q_values
[[1.5159634 1.2386811 0.7922025]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1440
[[1.5147737 1.2464206 0.7997574]] - model q_values
[[1.5147737 1.2464206 0.7997574]] - step_model q_values
[[1.5147737 1.2464206 0.7997574]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1441
[[1.5107346 1.2553241 0.8058964]] - model q_values
[[1.5107346 1.2553241 0.8058964]] - step_model q_values
[[1.5107346 1.2553241 0.8058964]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1442
[[1.5064223 1.2637949 0.8060564]] - model q_values
[[1.5064223 1.2637949 0.8060564]] - step_model q_values
[[1.5064223 1.2637949 0.8060564]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1443
[[1.5003939 1.2741904 0.8067312]] - model q_values
[[1.5003939 1.2741904 0.8067312]] - step_model q_values
[[1.5003939 1.2741904 0.8067312]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1444
[[1.492075  1.2857516 0.8106283]] - model q_values
[[1.492075  1.2857516 0.8106283]] - step_model q_values
[[1.492075  1.2857516 0.8106283]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1445
[[1.4802241 1.2973648 0.8190202]] - model q_values
[[1.4802241 1.2973648 0.8190202]] - step_model q_values
[[1.4802241 1.2973648 0.8190202]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1446
[[1.4682003  1.3088692  0.82046723]] - model q_values
[[1.4682003  1.3088692  0.82046723]] - step_model q_values
[[1.4682003  1.3088692  0.82046723]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1447
[[1.4596733 1.3227024 0.8091111]] - model q_values
[[1.4596733 1.3227024 0.8091111]] - step_model q_values
[[1.4596733 1.3227024 0.8091111]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1448
[[1.4502617  1.3354789  0.80312765]] - model q_values
[[1.4502617  1.3354789  0.80312765]] - step_model q_values
[[1.4502617  1.3354789  0.80312765]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1449
[[1.4438281  1.3499516  0.78410614]] - model q_values
[[1.4438281  1.3499516  0.78410614]] - step_model q_values
[[1.4438281  1.3499516  0.78410614]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1450
[[1.4396069 1.3651947 0.7554701]] - model q_values
[[1.4396069 1.3651947 0.7554701]] - step_model q_values
[[1.4396069 1.3651947 0.7554701]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1451
[[1.4344046  1.380377   0.72762287]] - model q_values
[[1.4344046  1.380377   0.72762287]] - step_model q_values
[[1.4344046  1.380377   0.72762287]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1452
[[1.4280053 1.3948312 0.7057482]] - model q_values
[[1.4280053 1.3948312 0.7057482]] - step_model q_values
[[1.4280053 1.3948312 0.7057482]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1453
[[1.4215102 1.4067076 0.6860949]] - model q_values
[[1.4215102 1.4067076 0.6860949]] - step_model q_values
[[1.4215102 1.4067076 0.6860949]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1454
[[1.4148722  1.420866   0.66828835]] - model q_values
[[1.4148722  1.420866   0.66828835]] - step_model q_values
[[1.4148722  1.420866   0.66828835]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1455
[[-0.21923259  0.22963807  0.46359578]] - model q_values
[[-0.21923259  0.22963807  0.46359578]] - step_model q_values
[[-0.21923259  0.22963807  0.46359578]] - double_policy q_values
[[-0.8499644   0.99648994  3.5571454 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1456
[[1.395725   1.4447867  0.64094913]] - model q_values
[[1.395725   1.4447867  0.64094913]] - step_model q_values
[[1.395725   1.4447867  0.64094913]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1457
[[-0.23655303  0.2423641   0.4544928 ]] - model q_values
[[-0.23655303  0.2423641   0.4544928 ]] - step_model q_values
[[-0.23655303  0.2423641   0.4544928 ]] - double_policy q_values
[[-0.8499644   0.99648994  3.5571454 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1458
[[1.3733832  1.4647806  0.63760287]] - model q_values
[[1.3733832  1.4647806  0.63760287]] - step_model q_values
[[1.3733832  1.4647806  0.63760287]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1459
[[-0.25368208  0.25302744  0.45927936]] - model q_values
[[-0.25368208  0.25302744  0.45927936]] - step_model q_values
[[-0.25368208  0.25302744  0.45927936]] - double_policy q_values
[[-0.8499644   0.99648994  3.5571454 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1460
[[1.3502557 1.4791667 0.6613399]] - model q_values
[[1.3502557 1.4791667 0.6613399]] - step_model q_values
[[1.3502557 1.4791667 0.6613399]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1461
[[-0.2674945   0.25704497  0.48594868]] - model q_values
[[-0.2674945   0.25704497  0.48594868]] - step_model q_values
[[-0.2674945   0.25704497  0.48594868]] - double_policy q_values
[[-0.8499644   0.99648994  3.5571454 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1462
[[1.3275524 1.485776  0.7089031]] - model q_values
[[1.3275524 1.485776  0.7089031]] - step_model q_values
[[1.3275524 1.485776  0.7089031]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1463
[[-0.27874577  0.25716764  0.5514037 ]] - model q_values
[[-0.27874577  0.25716764  0.5514037 ]] - step_model q_values
[[-0.27874577  0.25716764  0.5514037 ]] - double_policy q_values
[[-0.8499644   0.99648994  3.5571454 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1464
[[1.3040578 1.4890355 0.8109858]] - model q_values
[[1.3040578 1.4890355 0.8109858]] - step_model q_values
[[1.3040578 1.4890355 0.8109858]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1465
[[-0.2879171   0.25774896  0.6307084 ]] - model q_values
[[-0.2879171   0.25774896  0.6307084 ]] - step_model q_values
[[-0.2879171   0.25774896  0.6307084 ]] - double_policy q_values
[[-0.8499644   0.99648994  3.5571454 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1466
[[1.2848834 1.4908311 0.9101943]] - model q_values
[[1.2848834 1.4908311 0.9101943]] - step_model q_values
[[1.2848834 1.4908311 0.9101943]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1467
[[-0.29473782  0.26051915  0.72896737]] - model q_values
[[-0.29473782  0.26051915  0.72896737]] - step_model q_values
[[-0.29473782  0.26051915  0.72896737]] - double_policy q_values
[[-0.8499644   0.99648994  3.5571454 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1468
[[1.2606109 1.5058391 1.0377761]] - model q_values
[[1.2606109 1.5058391 1.0377761]] - step_model q_values
[[1.2606109 1.5058391 1.0377761]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1469
[[-0.27068818  0.29605395  0.86526024]] - model q_values
[[-0.27068818  0.29605395  0.86526024]] - step_model q_values
[[-0.27068818  0.29605395  0.86526024]] - double_policy q_values
[[-0.8499644   0.99648994  3.5571454 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1470
[[1.2374437 1.5150807 1.1528428]] - model q_values
[[1.2374437 1.5150807 1.1528428]] - step_model q_values
[[1.2374437 1.5150807 1.1528428]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1471
[[-0.22585091  0.35048515  1.0201432 ]] - model q_values
[[-0.22585091  0.35048515  1.0201432 ]] - step_model q_values
[[-0.22585091  0.35048515  1.0201432 ]] - double_policy q_values
[[-0.8499644   0.99648994  3.5571454 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1472
[[1.2180202 1.5232286 1.2467332]] - model q_values
[[1.2180202 1.5232286 1.2467332]] - step_model q_values
[[1.2180202 1.5232286 1.2467332]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1473
[[-0.18783683  0.39363146  1.1372247 ]] - model q_values
[[-0.18783683  0.39363146  1.1372247 ]] - step_model q_values
[[-0.18783683  0.39363146  1.1372247 ]] - double_policy q_values
[[-0.8499644   0.99648994  3.5571454 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1474
[[1.2321873 1.5536199 1.3532008]] - model q_values
[[1.2321873 1.5536199 1.3532008]] - step_model q_values
[[1.2321873 1.5536199 1.3532008]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1475
[[-0.13903528  0.44650158  1.2755628 ]] - model q_values
[[-0.13903528  0.44650158  1.2755628 ]] - step_model q_values
[[-0.13903528  0.44650158  1.2755628 ]] - double_policy q_values
[[-0.8499644   0.99648994  3.5571454 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1476
[[1.2708077 1.6197561 1.5048128]] - model q_values
[[1.2708077 1.6197561 1.5048128]] - step_model q_values
[[1.2708077 1.6197561 1.5048128]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1477
[[-0.07370526  0.520748    1.4481375 ]] - model q_values
[[-0.07370526  0.520748    1.4481375 ]] - step_model q_values
[[-0.07370526  0.520748    1.4481375 ]] - double_policy q_values
[[-0.8499644   0.99648994  3.5571454 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1478
[[1.3155453 1.703397  1.6862819]] - model q_values
[[1.3155453 1.703397  1.6862819]] - step_model q_values
[[1.3155453 1.703397  1.6862819]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1479
[[0.0602271  0.67012006 1.7023631 ]] - model q_values
[[0.0602271  0.67012006 1.7023631 ]] - step_model q_values
[[0.0602271  0.67012006 1.7023631 ]] - double_policy q_values
[[-0.8499644   0.99648994  3.5571454 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1480
[[1.4248525 1.8668836 1.9516034]] - model q_values
[[1.4248525 1.8668836 1.9516034]] - step_model q_values
[[1.4248525 1.8668836 1.9516034]] - double_policy q_values
[[1.8108543 2.0866494 5.3311224]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1481
[[1.0470228 1.3681781 2.2963488]] - model q_values
[[1.0470228 1.3681781 2.2963488]] - step_model q_values
[[1.0470228 1.3681781 2.2963488]] - double_policy q_values
[[2.7908823 2.2049165 7.1961727]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1482
[[4.3940635 4.3124914 1.8017665]] - model q_values
[[4.3940635 4.3124914 1.8017665]] - step_model q_values
[[4.3940635 4.3124914 1.8017665]] - double_policy q_values
[[0.8569356 2.3070254 2.0655103]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1483
[[4.7756577 4.6156373 1.9615436]] - model q_values
[[4.7756577 4.6156373 1.9615436]] - step_model q_values
[[4.7756577 4.6156373 1.9615436]] - double_policy q_values
[[1.0219138 2.4700675 1.8519031]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1484
[[5.402765 4.997389 2.339092]] - model q_values
[[5.402765 4.997389 2.339092]] - step_model q_values
[[5.402765 4.997389 2.339092]] - double_policy q_values
[[1.6074109 2.758976  2.0558257]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1485
[[5.908906  5.3410664 2.7407303]] - model q_values
[[5.908906  5.3410664 2.7407303]] - step_model q_values
[[5.908906  5.3410664 2.7407303]] - double_policy q_values
[[2.0679216 2.9915004 2.0934415]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1486
[[6.399988 5.653652 3.180414]] - model q_values
[[6.399988 5.653652 3.180414]] - step_model q_values
[[6.399988 5.653652 3.180414]] - double_policy q_values
[[2.637177  3.2006469 2.28132  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1487
[[1.6539357 2.0538492 4.308838 ]] - model q_values
[[1.6539357 2.0538492 4.308838 ]] - step_model q_values
[[1.6539357 2.0538492 4.308838 ]] - double_policy q_values
[[0.07800341 1.0722934  5.234832  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1488
[[2.5747042 2.8816206 3.8246326]] - model q_values
[[2.5747042 2.8816206 3.8246326]] - step_model q_values
[[2.5747042 2.8816206 3.8246326]] - double_policy q_values
[[1.9354621 1.6924827 5.7600517]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1489
[[2.7798975 2.9697983 3.8604684]] - model q_values
[[2.7798975 2.9697983 3.8604684]] - step_model q_values
[[2.7798975 2.9697983 3.8604684]] - double_policy q_values
[[1.7030478 1.4251608 5.880868 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1490
[[3.1220517 3.4824398 5.282669 ]] - model q_values
[[3.1220517 3.4824398 5.282669 ]] - step_model q_values
[[3.1220517 3.4824398 5.282669 ]] - double_policy q_values
[[-0.3284558   0.96598923  3.6739244 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1491
[[2.150736  2.6905398 5.2113814]] - model q_values
[[2.150736  2.6905398 5.2113814]] - step_model q_values
[[2.150736  2.6905398 5.2113814]] - double_policy q_values
[[0.07800341 1.0722934  5.234832  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1492
[[3.047925  3.5299978 4.6309414]] - model q_values
[[3.047925  3.5299978 4.6309414]] - step_model q_values
[[3.047925  3.5299978 4.6309414]] - double_policy q_values
[[1.9354621 1.6924827 5.7600517]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1493
[[3.2389874 3.6190093 4.562902 ]] - model q_values
[[3.2389874 3.6190093 4.562902 ]] - step_model q_values
[[3.2389874 3.6190093 4.562902 ]] - double_policy q_values
[[1.7030478 1.4251608 5.880868 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1494
[[3.421167  3.8959076 5.7050076]] - model q_values
[[3.421167  3.8959076 5.7050076]] - step_model q_values
[[3.421167  3.8959076 5.7050076]] - double_policy q_values
[[-0.3284558   0.96598923  3.6739244 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1495
[[2.324489  2.956322  5.3815837]] - model q_values
[[2.324489  2.956322  5.3815837]] - step_model q_values
[[2.324489  2.956322  5.3815837]] - double_policy q_values
[[0.07800341 1.0722934  5.234832  ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1496
[[3.1332958 3.7165642 4.5528455]] - model q_values
[[3.1332958 3.7165642 4.5528455]] - step_model q_values
[[3.1332958 3.7165642 4.5528455]] - double_policy q_values
[[1.9354621 1.6924827 5.7600517]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1497
[[3.2045445 3.6845977 4.2398667]] - model q_values
[[3.2045445 3.6845977 4.2398667]] - step_model q_values
[[3.2045445 3.6845977 4.2398667]] - double_policy q_values
[[1.7030478 1.4251608 5.880868 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1498
[[3.2901053 3.8680956 5.2234535]] - model q_values
[[3.2901053 3.8680956 5.2234535]] - step_model q_values
[[3.2901053 3.8680956 5.2234535]] - double_policy q_values
[[-0.3284558   0.96598923  3.6739244 ]] - target_policy q_values
Training
_max_priority:  47.9268

num_timesteps:  1499
[[2.2113912 2.8792837 4.8300595]] - model q_values
[[2.2113912 2.8792837 4.8300595]] - step_model q_values
[[2.2113912 2.8792837 4.8300595]] - double_policy q_values
[[0.07800341 1.0722934  5.234832  ]] - target_policy q_values
Training
_max_priority:  47.9268
Updating target network

