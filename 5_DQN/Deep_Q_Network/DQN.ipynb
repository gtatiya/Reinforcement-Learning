{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym # openAi gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from gym import envs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "# Deep Q Network off-policy\n",
    "class DeepQNetwork:\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_actions,\n",
    "            n_features,\n",
    "            learning_rate=0.01,\n",
    "            reward_decay=0.9,\n",
    "            e_greedy=0.9,\n",
    "            replace_target_iter=300,\n",
    "            memory_size=500,\n",
    "            batch_size=32,\n",
    "            e_greedy_increment=None,\n",
    "            output_graph=False,\n",
    "            layers=[10]\n",
    "    ):\n",
    "        self.n_actions = n_actions\n",
    "        self.n_features = n_features\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.epsilon_max = e_greedy\n",
    "        self.replace_target_iter = replace_target_iter\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon_increment = e_greedy_increment\n",
    "        self.hidden_layer_sizes = layers\n",
    "        #self.epsilon = 0 if e_greedy_increment is not None else self.epsilon_max\n",
    "        \n",
    "        if e_greedy_increment is not None:\n",
    "            self.epsilon = 0\n",
    "        else:\n",
    "            self.epsilon = self.epsilon_max\n",
    "\n",
    "        # total learning step\n",
    "        self.learn_step_counter = 0\n",
    "\n",
    "        # initialize zero memory [s, a, r, s_]\n",
    "        self.memory = np.zeros((self.memory_size, n_features * 2 + 2))\n",
    "        #print(\"self.memory: \", self.memory.shape) #self.memory:  (2000, 6)\n",
    "        self.memory_counter = 0\n",
    "\n",
    "        # consist of [target_net, evaluate_net]\n",
    "        self._build_net()\n",
    "        t_params = tf.get_collection('target_net_params')\n",
    "        print(\"t_params: \", t_params)\n",
    "        e_params = tf.get_collection('eval_net_params')    \n",
    "        print(\"e_params: \", e_params)\n",
    "        \n",
    "        # all tensors\n",
    "        #print(\"tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES): \", tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES))\n",
    "        \n",
    "        # tf.assign(ref, value): Update 'ref' by assigning 'value' to it\n",
    "        self.replace_target_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)]\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "        if output_graph:\n",
    "            # $ tensorboard --logdir=logs\n",
    "            # tf.train.SummaryWriter soon be deprecated, use following\n",
    "            tf.summary.FileWriter(\"logs/\", self.sess.graph)\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        self.cost_his = []\n",
    "\n",
    "    def _build_net(self):\n",
    "        # ------------------ build evaluate_net ------------------\n",
    "        self.s = tf.placeholder(tf.float32, [None, self.n_features], name='s')  # input\n",
    "        print(\"self.s: \", self.s)\n",
    "        self.q_target = tf.placeholder(tf.float32, [None, self.n_actions], name='Q_target')  # for calculating loss\n",
    "        print(\"self.q_target: \", self.q_target)\n",
    "        \n",
    "        \n",
    "        with tf.variable_scope('eval_net'):\n",
    "            # c_names(collections_names) are the collections to store variables\n",
    "            c_names = ['eval_net_params', tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "            w_initializer = tf.random_normal_initializer(0., 0.3)\n",
    "            b_initializer = tf.constant_initializer(0.1)  # config of layers\n",
    "            print(\"c_names, w_initializer, b_initializer: \", c_names, w_initializer, b_initializer)\n",
    "            \n",
    "            # collections is used later when assign to target net\n",
    "            for i in range(1, len(self.hidden_layer_sizes)+1):\n",
    "                if i == 1:\n",
    "                    with tf.variable_scope('layer'+str(i)):\n",
    "                        w = tf.get_variable('w'+str(i), [self.n_features, self.hidden_layer_sizes[i-1]], initializer=w_initializer, collections=c_names)\n",
    "                        b = tf.get_variable('b'+str(i), [1, self.hidden_layer_sizes[i-1]], initializer=b_initializer, collections=c_names)\n",
    "                        net = tf.nn.relu(tf.matmul(self.s, w) + b)\n",
    "                        print('layer'+str(i), net)\n",
    "                else:\n",
    "                    with tf.variable_scope('layer'+str(i)):\n",
    "                        w = tf.get_variable('w'+str(i), [self.hidden_layer_sizes[i-2], self.hidden_layer_sizes[i-1]], initializer=w_initializer, collections=c_names)\n",
    "                        b = tf.get_variable('b'+str(i), [1, self.hidden_layer_sizes[i-1]], initializer=b_initializer, collections=c_names)\n",
    "                        net = tf.nn.relu(tf.matmul(net, w) + b)\n",
    "                        print('layer'+str(i), net)\n",
    "            # last layer. collections is used later when assign to target net\n",
    "            with tf.variable_scope('final_layer'):\n",
    "                w = tf.get_variable('w_final_layer', [self.hidden_layer_sizes[-1], self.n_actions], initializer=w_initializer, collections=c_names)\n",
    "                b = tf.get_variable('b_final_layer', [1, self.n_actions], initializer=b_initializer, collections=c_names)\n",
    "                self.q_eval = tf.matmul(net, w) + b\n",
    "                print(\"self.q_eval: \", self.q_eval)\n",
    "                \n",
    "            \n",
    "        with tf.variable_scope('loss'):\n",
    "            self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_eval))\n",
    "            print(\"self.loss: \", self.loss)\n",
    "            \n",
    "        with tf.variable_scope('train'):\n",
    "            #self._train_op = tf.train.RMSPropOptimizer(self.lr).minimize(self.loss)\n",
    "            self._train_op = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.loss)\n",
    "            #print(\"self._train_op: \", self._train_op)\n",
    "\n",
    "        # ------------------ build target_net ------------------\n",
    "        self.s_ = tf.placeholder(tf.float32, [None, self.n_features], name='s_')    # input\n",
    "        print(\"self.s_: \", self.s_)\n",
    "        with tf.variable_scope('target_net'):\n",
    "            # c_names(collections_names) are the collections to store variables\n",
    "            c_names = ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "\n",
    "            for i in range(1, len(self.hidden_layer_sizes)+1):\n",
    "                if i == 1:\n",
    "                    with tf.variable_scope('layer'+str(i)):\n",
    "                        w = tf.get_variable('w'+str(i), [self.n_features, self.hidden_layer_sizes[i-1]], initializer=w_initializer, collections=c_names)\n",
    "                        b = tf.get_variable('b'+str(i), [1, self.hidden_layer_sizes[i-1]], initializer=b_initializer, collections=c_names)\n",
    "                        net = tf.nn.relu(tf.matmul(self.s_, w) + b)\n",
    "                        print('layer'+str(i), net)\n",
    "                else:\n",
    "                    with tf.variable_scope('layer'+str(i)):\n",
    "                        w = tf.get_variable('w'+str(i), [self.hidden_layer_sizes[i-2], self.hidden_layer_sizes[i-1]], initializer=w_initializer, collections=c_names)\n",
    "                        b = tf.get_variable('b'+str(i), [1, self.hidden_layer_sizes[i-1]], initializer=b_initializer, collections=c_names)\n",
    "                        net = tf.nn.relu(tf.matmul(net, w) + b)\n",
    "                        print('layer'+str(i), net)\n",
    "            # last layer. collections is used later when assign to target net\n",
    "            with tf.variable_scope('final_layer'):\n",
    "                w = tf.get_variable('w_final_layer', [self.hidden_layer_sizes[-1], self.n_actions], initializer=w_initializer, collections=c_names)\n",
    "                b = tf.get_variable('b_final_layer', [1, self.n_actions], initializer=b_initializer, collections=c_names)\n",
    "                self.q_next = tf.matmul(net, w) + b\n",
    "                print(\"self.q_next: \", self.q_next)\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        \"\"\"\n",
    "        observation = np.array([-0.5, -0.5])\n",
    "        print(\"observation: \", observation.shape) #observation:  (2,)\n",
    "        observation = observation[np.newaxis, :]\n",
    "        print(\"observation: \", observation.shape) #observation:  (1, 2)\n",
    "        \"\"\"\n",
    "        # to have batch dimension when feed into tf placeholder\n",
    "        observation = observation[np.newaxis, :]\n",
    "        \n",
    "        \"\"\"\n",
    "        np.random.uniform(): [0, 1)\n",
    "        \"\"\"\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            # forward feed the observation and get q value for every actions\n",
    "            actions_value = self.sess.run(self.q_eval, feed_dict={self.s: observation})\n",
    "            action = np.argmax(actions_value)\n",
    "            #print(\"actions_value: \", actions_value)\n",
    "            #print(\"action: \", action)\n",
    "        else:\n",
    "            # Explore\n",
    "            action = np.random.randint(low=0, high=self.n_actions)\n",
    "        return action\n",
    "    \n",
    "    \n",
    "    def store_transition(self, s, a, r, s_):\n",
    "#         if not hasattr(self, 'memory_counter'):\n",
    "#             self.memory_counter = 0\n",
    "\n",
    "        #transition = np.hstack((s, [a, r], s_))\n",
    "        transition = np.hstack((s, a, r, s_))\n",
    "        #print(\"transition: \", transition) #[-0.5 -0.5  0.   0.  -0.5 -0.5]\n",
    "\n",
    "        # replace the old memory with new memory\n",
    "        index = self.memory_counter % self.memory_size\n",
    "        #print(\"index: \", index)\n",
    "        self.memory[index, :] = transition\n",
    "\n",
    "        self.memory_counter += 1\n",
    "        #print(\"self.memory_counter: \", self.memory_counter) # from 0 until 'game over'\n",
    "        \n",
    "        \n",
    "    def learn(self):\n",
    "        # check to replace target parameters\n",
    "        # Update target network every self.replace_target_iter (e.g. 200) times\n",
    "        if self.learn_step_counter % self.replace_target_iter == 0:\n",
    "            #print(\"self.learn_step_counter: \", self.learn_step_counter)\n",
    "            #print(\"self.cost_his: \", len(self.cost_his))\n",
    "            self.sess.run(self.replace_target_op)\n",
    "            print('target_params_replaced\\n')\n",
    "\n",
    "        # sample batch memory from all memory\n",
    "        \"\"\"\n",
    "        Why taking random memory instead of all the memory - batch_size?\n",
    "        \"\"\"\n",
    "        if self.memory_counter > self.memory_size:\n",
    "            sample_index = np.random.choice(self.memory_size, size=self.batch_size)\n",
    "        else:\n",
    "            #print(\"self.memory_counter: \", self.memory_counter)\n",
    "            # this is only for first 200 to 2000 memories\n",
    "            sample_index = np.random.choice(self.memory_counter, size=self.batch_size)\n",
    "        batch_memory = self.memory[sample_index, :]\n",
    "        #print(\"batch_memory: \", batch_memory.shape) #batch_memory:  (32, 6)\n",
    "        #print(\"batch_memory 1: \", batch_memory[0]) #batch_memory 1:  [-0.5   0.25  0.    0.   -0.5   0.  ]\n",
    "        #print(\"batch_memory 2: \", batch_memory[0, -self.n_features:]) #batch_memory 2:  [-0.5  0. ]\n",
    "        #print(\"batch_memory 3: \", batch_memory[0, :self.n_features]) #batch_memory 3:  [-0.5   0.25]\n",
    "\n",
    "        q_next, q_eval = self.sess.run(\n",
    "            [self.q_next, self.q_eval],\n",
    "            feed_dict={\n",
    "                self.s_: batch_memory[:, -self.n_features:],  # fixed params\n",
    "                self.s: batch_memory[:, :self.n_features],  # newest params\n",
    "            })\n",
    "\n",
    "        # change q_target w.r.t q_eval's action\n",
    "        q_target = q_eval.copy()\n",
    "        #print(\"q_target.shape: \", q_target.shape) #q_target:  (32, 4)\n",
    "\n",
    "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "        eval_act_index = batch_memory[:, self.n_features].astype(int) # actions\n",
    "        #print(\"eval_act_index.shape: \", eval_act_index.shape) #eval_act_index.shape:  (32,)\n",
    "        reward = batch_memory[:, self.n_features + 1] # rewards\n",
    "        #print(\"reward.shape: \", reward.shape) #reward.shape:  (32,)\n",
    "        \n",
    "        \"\"\"\n",
    "        WRONG:\n",
    "        q_target[batch_index, eval_act_index] - Q value of action taken\n",
    "        We replace this Q value with reward of current state + Q value of next state\n",
    "        \n",
    "        We are trying to minimize the distance between Q values of current state and Q values of next state,\n",
    "        but because we are adding reward (reward + self.gamma * np.max(q_next, axis=1))\n",
    "        the distance becomes larger when reward is bigger and reducing this distance leads us to higher rewards.    \n",
    "        \n",
    "        1. q_eval: Delete the Q value of the action taken\n",
    "        2. q_target: For deleted Q value, use the Q value of corresponding action of next state:\n",
    "            reward + self.gamma * np.max(q_next, axis=1)\n",
    "        3. q_eval - q_target\n",
    "        4. Minimize\n",
    "        \"\"\"\n",
    "        #print(\"q_target[0]: \", q_target[0])\n",
    "        #print(\"eval_act_index[0]: \", eval_act_index[0])\n",
    "        q_target[batch_index, eval_act_index] = reward + self.gamma * np.max(q_next, axis=1)\n",
    "\n",
    "        \"\"\"\n",
    "        For example in this batch I have 2 samples and 3 actions:\n",
    "        q_eval =\n",
    "        [[1, 2, 3],\n",
    "         [4, 5, 6]]\n",
    "\n",
    "        q_target = q_eval =\n",
    "        [[1, 2, 3],\n",
    "         [4, 5, 6]]\n",
    "\n",
    "        Then change q_target with the real q_target value w.r.t the q_eval's action.\n",
    "        For example in:\n",
    "            sample 0, I took action 0, and the max q_target value is -1;\n",
    "            sample 1, I took action 2, and the max q_target value is -2:\n",
    "        q_target =\n",
    "        [[-1, 2, 3],\n",
    "         [4, 5, -2]]\n",
    "\n",
    "        So the (q_target - q_eval) becomes:\n",
    "        [[(-1)-(1), 0, 0],\n",
    "         [0, 0, (-2)-(6)]]\n",
    "\n",
    "        We then backpropagate this error w.r.t the corresponding action to network,\n",
    "        leave other action as error=0 cause we didn't choose it.\n",
    "        \"\"\"\n",
    "\n",
    "        # train eval network\n",
    "        _, self.cost = self.sess.run([self._train_op, self.loss],\n",
    "                                     feed_dict={self.s: batch_memory[:, :self.n_features],\n",
    "                                                self.q_target: q_target})\n",
    "        self.cost_his.append(self.cost)\n",
    "\n",
    "        # increasing epsilon\n",
    "        #self.epsilon = self.epsilon + self.epsilon_increment if self.epsilon < self.epsilon_max else self.epsilon_max\n",
    "        if self.epsilon < self.epsilon_max:\n",
    "            #print(\"increasing epsilon\")\n",
    "            self.epsilon = self.epsilon + self.epsilon_increment\n",
    "        else:\n",
    "            self.epsilon = self.epsilon_max\n",
    "        \n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        \n",
    "    def plot_cost(self):\n",
    "        plt.plot(np.arange(len(self.cost_his)), self.cost_his)\n",
    "        plt.ylabel('Cost')\n",
    "        plt.xlabel('training steps')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "env.n_actions:  Discrete(3)\n",
      "env.n_features:  Box(2,)\n",
      "action_space:  3\n",
      "observation_space:  2\n",
      "observation_space - high:  [0.6  0.07]\n",
      "observation_space: - low:  [-1.2  -0.07]\n",
      "self.s:  Tensor(\"s:0\", shape=(?, 2), dtype=float32)\n",
      "self.q_target:  Tensor(\"Q_target:0\", shape=(?, 3), dtype=float32)\n",
      "c_names, w_initializer, b_initializer:  ['eval_net_params', 'variables'] <tensorflow.python.ops.init_ops.RandomNormal object at 0x000001B8AF6A77B8> <tensorflow.python.ops.init_ops.Constant object at 0x000001B8AF6A77F0>\n",
      "layer1 Tensor(\"eval_net/layer1/Relu:0\", shape=(?, 100), dtype=float32)\n",
      "layer2 Tensor(\"eval_net/layer2/Relu:0\", shape=(?, 100), dtype=float32)\n",
      "layer3 Tensor(\"eval_net/layer3/Relu:0\", shape=(?, 100), dtype=float32)\n",
      "self.q_eval:  Tensor(\"eval_net/final_layer/add:0\", shape=(?, 3), dtype=float32)\n",
      "self.loss:  Tensor(\"loss/Mean:0\", shape=(), dtype=float32)\n",
      "self.s_:  Tensor(\"s_:0\", shape=(?, 2), dtype=float32)\n",
      "layer1 Tensor(\"target_net/layer1/Relu:0\", shape=(?, 100), dtype=float32)\n",
      "layer2 Tensor(\"target_net/layer2/Relu:0\", shape=(?, 100), dtype=float32)\n",
      "layer3 Tensor(\"target_net/layer3/Relu:0\", shape=(?, 100), dtype=float32)\n",
      "self.q_next:  Tensor(\"target_net/final_layer/add:0\", shape=(?, 3), dtype=float32)\n",
      "t_params:  [<tf.Variable 'target_net/layer1/w1:0' shape=(2, 100) dtype=float32_ref>, <tf.Variable 'target_net/layer1/b1:0' shape=(1, 100) dtype=float32_ref>, <tf.Variable 'target_net/layer2/w2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'target_net/layer2/b2:0' shape=(1, 100) dtype=float32_ref>, <tf.Variable 'target_net/layer3/w3:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'target_net/layer3/b3:0' shape=(1, 100) dtype=float32_ref>, <tf.Variable 'target_net/final_layer/w_final_layer:0' shape=(100, 3) dtype=float32_ref>, <tf.Variable 'target_net/final_layer/b_final_layer:0' shape=(1, 3) dtype=float32_ref>]\n",
      "e_params:  [<tf.Variable 'eval_net/layer1/w1:0' shape=(2, 100) dtype=float32_ref>, <tf.Variable 'eval_net/layer1/b1:0' shape=(1, 100) dtype=float32_ref>, <tf.Variable 'eval_net/layer2/w2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'eval_net/layer2/b2:0' shape=(1, 100) dtype=float32_ref>, <tf.Variable 'eval_net/layer3/w3:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'eval_net/layer3/b3:0' shape=(1, 100) dtype=float32_ref>, <tf.Variable 'eval_net/final_layer/w_final_layer:0' shape=(100, 3) dtype=float32_ref>, <tf.Variable 'eval_net/final_layer/b_final_layer:0' shape=(1, 3) dtype=float32_ref>]\n",
      "game over\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFDhJREFUeJzt3X2wJXV95/H3x2F0ETMggjzfDAKrOyIQvWJYSTIadCEmi1giEk3wASeusmzYiisu2RCtsgpjlnXXuBpUlESQnYqJkEh43PAQ8YE7CDrDZHSKBx2hRBMUISZkmO/+cfq61/Hce8/c+Z17OHPfr6pTp/vXv+7z/U3XzGe6+5zuVBWSJO2sJ426AEnSrsFAkSQ1YaBIkpowUCRJTRgokqQmDBRJUhMGiiSpCQNFktSEgSJJamK3URewmPbZZ59auXLlqMuQpLGybt2671XVvvP1W1KBsnLlSqampkZdhiSNlST3DdLPU16SpCYMFElSEwaKJKkJA0WS1ISBIklqwkCRJDVhoEiSmjBQJElNGCiSpCYMFElSEwaKJKkJA0WS1ISBIklqwkCRJDVhoEiSmjBQJElNGCiSpCYMFElSEwaKJKkJA0WS1ISBIklqwkCRJDVhoEiSmjBQJElNjCRQkuyd5Lok3+jenz5Lv/clWd+9TpvRniTvTfL1JBuTnL141UuS+hnVEcq5wA1VdQRwQzf/E5K8Ang+cAzwIuAdSVZ0i98AHAI8p6r+DXD5YhQtSZrdqALlZOCSbvoS4JV9+qwCbqqqrVX1KHAncGK37D8A76mqbQBV9eCQ65UkzWNUgbJfVT0A0L0/s0+fO4GTkjw1yT7AS+gdlQAcBpyWZCrJXyc5YlGqliTNardhbTjJ9cD+fRadN8j6VXVtkhcCtwLfBb4AbO0WPwX4p6qaTPIq4GLgF2apYw2wBmBiYmKHxiBJGlyqavE/NNkErK6qB5IcANxYVc+eZ53LgE9V1VVJ/g44saruTRLg+1W153yfOzk5WVNTU03GIElLRZJ1VTU5X79RnfK6Ejijmz4DuGL7DkmWJXlGN30UcBRwbbf4s8BLu+lfAr4+1GolSfMa2imveVwArE3yZuCbwKkASSaBt1bVmcBy4JbeAQgPA6+vqq0z1r80yTnAI8CZi1y/JGk7IwmUqvp74Jf7tE/RhUNV/RO9b3r1W//7wCuGWaMkacf4S3lJUhMGiiSpCQNFktSEgSJJasJAkSQ1YaBIkpowUCRJTRgokqQmDBRJUhMGiiSpCQNFktSEgSJJasJAkSQ1YaBIkpowUCRJTRgokqQmDBRJUhMGiiSpCQNFktSEgSJJasJAkSQ1YaBIkpowUCRJTRgokqQmDBRJUhMGiiSpCQNFktSEgSJJasJAkSQ1YaBIkpowUCRJTYwkUJLsneS6JN/o3p8+S7/3JVnfvU6b0f7LSW5PckeSv01y+OJVL0nqZ1RHKOcCN1TVEcAN3fxPSPIK4PnAMcCLgHckWdEt/jDwuqo6BrgM+N1FqVqSNKtRBcrJwCXd9CXAK/v0WQXcVFVbq+pR4E7gxG5ZAdPhsidw/xBrlSQNYLcRfe5+VfUAQFU9kOSZffrcCZyf5ELgqcBLgLu6ZWcCVyX5EfAw8POLULMkaQ5DC5Qk1wP791l03iDrV9W1SV4I3Ap8F/gCsLVbfA7wK1X1pSTvAC6kFzL96lgDrAGYmJjYoTFIkgaXqlr8D002Aau7o5MDgBur6tnzrHMZ8CngNuCLVXVY1z4BXF1Vq+b73MnJyZqamtr5AUjSEpJkXVVNztdvVNdQrgTO6KbPAK7YvkOSZUme0U0fBRwFXAs8BOyZ5F93XV8GbBx6xZKkOY3qGsoFwNokbwa+CZwKkGQSeGtVnQksB25JAr3rJK+vqq1dv7cAn0myjV7AvGnxhyBJmmkkp7xGxVNekrTjnuinvCRJuxgDRZLUhIEiSWrCQJEkNWGgSJKaMFAkSU0YKJKkJgwUSVITBookqQkDRZLUhIEiSWrCQJEkNWGgSJKaMFAkSU0YKJKkJgYKlCSHJXlKN706ydlJ9hpuaZKkcTLoEcpngMeTHA58HDgUuGxoVUmSxs6ggbKte/zuKcAHquoc4IDhlSVJGjeDBsq/JDkdOAP4q65t+XBKkiSNo0ED5Y3AccB7q+qeJIcCnxpeWZKkcbPbIJ2q6i7g7Bnz9wAXDKsoSdL4mTNQknwNqNmWV9VRzSuSJI2l+Y5QfrV7f3v3/qfd++uAfxxKRZKksTRnoFTVfQBJXlxVL56x6NwknwfeM8ziJEnjY9CL8nskOX56Jsm/BfYYTkmSpHE00EV54E3AJ5LsSe+ayg+6NkmSgAECJcmTgMOr6ugkK4BU1Q+GX5okaZzMe8qrqrYBZ3XTDxsmkqR+Br2Gcl2S30lySJK9p19DrUySNFZ25BoK/P+vD0PvWsqz2pYjSRpXAx2hVNWhfV4LDpMkpybZkGRbksk5+p2YZFOSzUnOndF+aJIvJflGkv+T5MkLrUWS1MbAD9hKcmSS1yT5zenXTnzueuBVwM1zfN4y4EPAScAq4PQkq7rF7wP+R1UdATwEvHknapEkNTDoA7bOBz7YvV4C/AHw7xf6oVW1sao2zdPtWGBzVd1dVY8BlwMnJwnwUuDPun6XAK9caC2SpDYGvYbyauBo4CtV9cYk+wEfG15ZABwEfGvG/BbgRcAzgO93z2eZbj9omIW8+y83cNf9Dw/zIyRpaFYduILzf+25Q/+cQQPlR1W1LcnW7rcoDzLPBfkk1wP791l0XlVdMcBnpk9bzdE+Wx1rgDUAExMTA3ysJGkhBg2Uqe4Z8h8F1gGPAF+ea4WqOmEna9sCHDJj/mDgfuB7wF5JduuOUqbbZ6vjIuAigMnJyVmDZy6LkeySNO4GfR7K27rJjyS5GlhRVV8dXlkA3AYc0T3M69vAa4Ffr6pK8jf0TsNdTu8pkoMc8UiShmjQi/J/kuQtSZ5TVffubJgkOSXJFnpPgfxckmu69gOTXAXQHX2cBVwDbATWVtWGbhPvBP5zks30rql8fGfqkSTtvFTNfxYoyUuB44FfoHft5A7g5qr6n8Mtr63JycmampoadRmSNFaSrKuqWX8zOG3QU17/N8lNwAvpfW34rcBzgbEKFEnS8AwUKEluoPf8ky8AtwAvrKoHh1mYJGm8DPpL+a8CjwFHAkcBRybZfWhVSZLGzqCnvM4BSPI04I3AJ+j9xuQpwytNkjROBj3ldRa9C/IvAO4DLqZ36kuSJGDwHzbuDlwIrJtxyxNJkn5s0NvXvx9YDvwGQJJ9ux8cSpIE7Njdht8JvKtrWg58alhFSZLGz6Df8jqF3u3qHwWoqvuBnxlWUZKk8TNooDxWvZ/UF0CSPYZXkiRpHA0aKGuT/DG9u/y+Bbie4T8PRZI0Rgb9HcofJnkZ8DDwbOD3quq6oVYmSRorg35tmC5AroPe896TvK6qLh1aZZKksTLnKa8kK5K8K8kfJXl5es4C7gZeszglSpLGwXxHKH8KPETvppBnAu8AngycXFV3DLk2SdIYmS9QnlVVzwNI8jF6j9+dqKofDr0ySdJYme9bXv8yPVFVjwP3GCaSpH7mO0I5OsnD3XSA3bv5AFVVK4ZanSRpbMwZKFW1bLEKkSSNt0F/2ChJ0pwMFElSEwaKJKkJA0WS1ISBIklqwkCRJDVhoEiSmjBQJElNGCiSpCYMFElSEwaKJKkJA0WS1MRIAiXJqUk2JNmWZHKOficm2ZRkc5JzZ7Rf2rWvT3JxkuWLU7kkaTajOkJZD7wKuHm2DkmWAR8CTgJWAacnWdUtvhR4DvA8YHd6T5OUJI3QfM9DGYqq2giQZK5uxwKbq+ruru/lwMnAXVV11XSnJF8GDh5etZKkQTyRr6EcBHxrxvyWru3HulNdvwFcvYh1SZL6GNoRSpLrgf37LDqvqq4YZBN92mq7+f8N3FxVt8xRxxpgDcDExMQAHytJWoihBUpVnbCTm9gCHDJj/mDg/umZJOcD+wK/NU8dFwEXAUxOTm4fSJKkRp7Ip7xuA45IcmiSJwOvBa4ESHIm8O+A06tq2whrlCR1RvW14VOSbAGOAz6X5Jqu/cAkVwFU1VbgLOAaYCOwtqo2dJv4CLAf8IUkdyT5vUUfhCTpJ6Rq6ZwFmpycrKmpqVGXIUljJcm6qpr1N4PTnsinvCRJY8RAkSQ1YaBIkpowUCRJTRgokqQmDBRJUhMGiiSpCQNFktSEgSJJasJAkSQ1YaBIkpowUCRJTRgokqQmDBRJUhMGiiSpCQNFktSEgSJJasJAkSQ1YaBIkpowUCRJTRgokqQmDBRJUhMGiiSpCQNFktSEgSJJasJAkSQ1YaBIkpowUCRJTRgokqQmDBRJUhMjCZQkpybZkGRbksk5+p2YZFOSzUnO7bP8g0keGW61kqRBjOoIZT3wKuDm2TokWQZ8CDgJWAWcnmTVjOWTwF5DrlOSNKCRBEpVbayqTfN0OxbYXFV3V9VjwOXAyfDjsHk/8F+GW6kkaVBP5GsoBwHfmjG/pWsDOAu4sqoeWPSqJEl97TasDSe5Hti/z6LzquqKQTbRp62SHAicCqwesI41wBqAiYmJQVaRJC3A0AKlqk7YyU1sAQ6ZMX8wcD/wc8DhwOYkAE9NsrmqDp+ljouAiwAmJydrJ2uSJM1iaIHSwG3AEUkOBb4NvBb49arawIwjnySPzBYmkqTFM6qvDZ+SZAtwHPC5JNd07QcmuQqgqrbSu1ZyDbARWNuFiSTpCShVS+cs0OTkZE1NTY26DEkaK0nWVdWsvxmc9kT+lpckaYwYKJKkJgwUSVITBookqQkDRZLUhIEiSWrCQJEkNWGgSJKaMFAkSU0YKJKkJgwUSVITBookqQkDRZLUhIEiSWrCQJEkNWGgSJKaMFAkSU0YKJKkJgwUSVITBookqQkDRZLUhIEiSWrCQJEkNWGgSJKaMFAkSU2kqkZdw6JJ8l3gvgWuvg/wvYbljJOlPHZY2uNfymOHpT3+mWP/2arad74VllSg7IwkU1U1Oeo6RmEpjx2W9viX8thhaY9/IWP3lJckqQkDRZLUhIEyuItGXcAILeWxw9Ie/1IeOyzt8e/w2L2GIklqwiMUSVITBsoAkpyYZFOSzUnOHXU9iynJvUm+luSOJFOjrmfYklyc5MEk62e07Z3kuiTf6N6fPsoah2WWsf9+km93+/+OJL8yyhqHJckhSf4mycYkG5L8p659l9/3c4x9h/e9p7zmkWQZ8HXgZcAW4Dbg9Kq6a6SFLZIk9wKTVbUkvouf5BeBR4A/qaoju7Y/AP6hqi7o/kPx9Kp65yjrHIZZxv77wCNV9YejrG3YkhwAHFBVtyf5GWAd8ErgDezi+36Osb+GHdz3HqHM71hgc1XdXVWPAZcDJ4+4Jg1JVd0M/MN2zScDl3TTl9D7y7bLmWXsS0JVPVBVt3fTPwQ2AgexBPb9HGPfYQbK/A4CvjVjfgsL/MMeUwVcm2RdkjWjLmZE9quqB6D3lw945ojrWWxnJflqd0pslzvls70kK4GfA77EEtv3240ddnDfGyjzS5+2pXSe8MVV9XzgJODt3WkRLR0fBg4DjgEeAP77aMsZriRPAz4D/HZVPTzqehZTn7Hv8L43UOa3BThkxvzBwP0jqmXRVdX93fuDwF/QOwW41HynO888fb75wRHXs2iq6jtV9XhVbQM+yi68/5Msp/cP6qVV9edd85LY9/3GvpB9b6DM7zbgiCSHJnky8FrgyhHXtCiS7NFdpCPJHsDLgfVzr7VLuhI4o5s+A7hihLUsqul/TDunsIvu/yQBPg5srKoLZyza5ff9bGNfyL73W14D6L4u9wFgGXBxVb13xCUtiiTPondUArAbcNmuPvYknwZW07vT6neA84HPAmuBCeCbwKlVtctdvJ5l7KvpnfIo4F7gt6avKexKkhwP3AJ8DdjWNf9XetcSdul9P8fYT2cH972BIklqwlNekqQmDBRJUhMGiiSpCQNFktSEgSJJasJA0ZKWZK8kb1vgulcl2WuePu9JcsLCqhuohjckOXBY25d2hF8b1pLW3bvor6bvrrvdsmVV9fiiF7UDktwI/E5V7fKPFtATn0coWuouAA7rnvfw/iSru2dDXEbvh14k+Wx3c8wNM2+Q2T0rZp8kK7tnSXy063Ntkt27Pp9M8uoZ/d+d5PbuGTPP6dr37Z61cXuSP05yX5J9ZhaZZFm3rfXduud0250ELu3q3z3JC5Lc1NV7zYzbhtyY5ANJbu22cWzX/ksznnfxlek7I0gLUlW+fC3ZF7ASWD9jfjXwKHDojLa9u/fd6d1+4hnd/L30flW+EtgKHNO1rwVe301/Enj1jP7/sZt+G/CxbvqPgHd10yfS+2XyPtvV+QLguhnze3XvN9J7Xg3AcuBWYN9u/jR6d3aY7vfRbvoXp8cM/CW9G4ACPA3YbdT7xNf4vjxCkX7al6vqnhnzZye5E/givRuFHtFnnXuq6o5ueh29kOnnz/v0OZ7ec3aoqquBh/qsdzfwrCQfTHIi0O9OuM8GjgSuS3IH8Lv0bmY67dPdZ9wMrOiu/3weuDDJ2fRCaussdUvzMlCkn/bo9ESS1cAJwHFVdTTwFeBf9Vnnn2dMP07v3mf9/HOfPv0ekfATquoh4Gh6RxpvBz7Wp1uADVV1TPd6XlW9fOZmfnqzdQFwJr2jry9On4aTFsJA0VL3Q2Cu6wZ7Ag9V1T92/9j+/BBq+Ft6j1slycuBn3qQUXdN5UlV9RngvwHP7xbNrH8TsG+S47p1lid57ozNnNa1Hw/8oKp+kOSwqvpaVb0PmAIMFC3YbP+LkpaEqvr7JJ9Psh74a+Bz23W5Gnhrkq/S+wf7i0Mo493Ap5OcBtxE72FGP9yuz0HAJ5JM/yfwXd37J4GPJPkRcBzwauB/JdmT3t/vDwAbur4PJbkVWAG8qWv77SQvoXfEdBe9PwNpQfzasDRiSZ4CPF5VW7ujiw9X1TGNP+NG/HqxhswjFGn0JoC13dHHY8BbRlyPtCAeoUiSmvCivCSpCQNFktSEgSJJasJAkSQ1YaBIkpowUCRJTfw/CdOqnxhlibUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classic control\n",
    "#env = gym.make('CartPole-v1')\n",
    "#env = gym.make('Pendulum-v0') # Not Working, requires changes in `action` before using `step`\n",
    "env = gym.make('MountainCar-v0')\n",
    "#env = gym.make('Acrobot-v1')\n",
    "\n",
    "# MuJoCo\n",
    "#env = gym.make('Swimmer-v2') # action_space: 2, observation_space: 8\n",
    "#env = gym.make('Hopper-v2') # action_space: 3, observation_space:  11\n",
    "#env = gym.make('Walker2d-v2') # action_space: 6, observation_space: 17\n",
    "#env = gym.make('HalfCheetah-v2') # action_space: 6, observation_space: 17\n",
    "#env = gym.make('Ant-v2') # action_space: 8, observation_space: 111\n",
    "#env = gym.make('HumanoidStandup-v2') # action_space: 17, observation_space: 376\n",
    "#env = gym.make('Humanoid-v2') # action_space: 17, observation_space: 376\n",
    "\n",
    "# Robotics\n",
    "#env = gym.make('FetchPickAndPlace-v1')\n",
    "#env = gym.make('FetchPush-v1')\n",
    "\n",
    "\n",
    "#env = env.unwrapped\n",
    "\n",
    "print(\"env.n_actions: \", env.action_space)\n",
    "print(\"env.n_features: \", env.observation_space)\n",
    "\n",
    "try:\n",
    "    num_actions = env.action_space.n\n",
    "except:\n",
    "    num_actions = env.action_space.shape[0]\n",
    "num_observations = env.observation_space.shape[0]\n",
    "\n",
    "print(\"action_space: \", num_actions)\n",
    "print(\"observation_space: \", num_observations)\n",
    "print(\"observation_space - high: \", env.observation_space.high)\n",
    "print(\"observation_space: - low: \", env.observation_space.low)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "RL = DeepQNetwork(num_actions, num_observations,\n",
    "                      learning_rate=0.001, #0.01,\n",
    "                      reward_decay=0.9,\n",
    "                      e_greedy=0.9,\n",
    "                      replace_target_iter=200,\n",
    "                      memory_size=2000,\n",
    "                      batch_size=200,\n",
    "                      # output_graph=True\n",
    "                      layers=[100, 100, 100])\n",
    "\n",
    "step = 0\n",
    "episodes = 25\n",
    "rewards_in_episode = []\n",
    "\n",
    "for episode in range(episodes):\n",
    "    # initial observation\n",
    "    observation = env.reset()\n",
    "    #print(\"observation: \", observation) # [-0.5, -0.5]\n",
    "    \n",
    "    rewards = []\n",
    "    while True:\n",
    "        # fresh env\n",
    "        #env.render()\n",
    "\n",
    "        # RL choose action based on observation and current network parameters\n",
    "        action = RL.choose_action(observation)\n",
    "        #print(\"action: \", action)\n",
    "\n",
    "        # RL take action and get next observation and reward\n",
    "        observation_, reward, done, info = env.step(action)\n",
    "        #print(\"observation_, reward, done: \", observation_, reward, done) #[-0.5 -0.5] 0 False\n",
    "        rewards.append(reward)\n",
    "        #print(\"reward: \", reward)\n",
    "\n",
    "        # swap observation\n",
    "        observation = observation_\n",
    "\n",
    "        # break while loop when end of this episode\n",
    "        if done:\n",
    "            break\n",
    "        step += 1\n",
    "        \n",
    "    rewards_mean = np.mean(np.array(rewards))\n",
    "    rewards_in_episode.append(rewards_mean)\n",
    "\n",
    "# end of game\n",
    "print('game over')\n",
    "env.close()\n",
    "\n",
    "plt.plot(np.arange(episodes), rewards_in_episode)\n",
    "plt.ylabel('Rewards')\n",
    "plt.xlabel('training steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  100\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  200\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  300\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  400\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  500\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  600\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  700\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  800\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  900\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  1000\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  1100\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  1200\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  1300\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  1400\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  1500\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  1600\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  1700\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  1800\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  1900\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  2000\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  2100\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  2200\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  2300\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  2400\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  2500\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  2600\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  2700\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  2800\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "episode:  2900\n",
      "reward:  -1.0\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "target_params_replaced\n",
      "\n",
      "game over\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "step = 0\n",
    "episodes = 3000\n",
    "rewards_in_episode = []\n",
    "\n",
    "for episode in range(3000):\n",
    "    if episode % 100 == 0:\n",
    "        print(\"episode: \", episode)\n",
    "        print(\"reward: \", reward)\n",
    "    # initial observation\n",
    "    observation = env.reset()\n",
    "    #print(\"observation: \", observation) # [-0.5, -0.5]\n",
    "    \n",
    "    rewards = []\n",
    "    while True:\n",
    "        # fresh env\n",
    "        #env.render()\n",
    "\n",
    "        # RL choose action based on observation and current network parameters\n",
    "        action = RL.choose_action(observation)\n",
    "        #print(\"action: \", action)\n",
    "\n",
    "        # RL take action and get next observation and reward\n",
    "        #observation_, reward, done = env.step(action)\n",
    "        #observation_, reward, done, info = env.step(action)\n",
    "        observation_, reward, done, info = env.step(np.array(action))\n",
    "        #print(\"observation_, reward, done: \", observation_, reward, done) #[-0.5 -0.5] 0 False\n",
    "        rewards.append(reward)\n",
    "        #print(\"reward: \", reward)\n",
    "\n",
    "        RL.store_transition(observation, action, reward, observation_)\n",
    "\n",
    "        # learn only when there are at least 200 memory and (step % 5 == 0)\n",
    "        if (step > 200) and (step % 5 == 0):\n",
    "            RL.learn()\n",
    "\n",
    "        # swap observation\n",
    "        observation = observation_\n",
    "\n",
    "        # break while loop when end of this episode\n",
    "        if done:\n",
    "            break\n",
    "        step += 1\n",
    "        \n",
    "    rewards_mean = np.mean(np.array(rewards))\n",
    "    rewards_in_episode.append(rewards_mean)\n",
    "\n",
    "# end of game\n",
    "print('game over')\n",
    "env.close()\n",
    "\n",
    "RL.plot_cost()\n",
    "\n",
    "plt.plot(np.arange(episodes), rewards_in_episode)\n",
    "plt.ylabel('Rewards')\n",
    "plt.xlabel('training steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
